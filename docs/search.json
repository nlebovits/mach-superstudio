[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mach-superstudio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "mach-superstudio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html#clustering",
    "href": "index.html#clustering",
    "title": "mach-superstudio",
    "section": "Clustering",
    "text": "Clustering\nLorum ipsum"
  },
  {
    "objectID": "mach-superstudio.html",
    "href": "mach-superstudio.html",
    "title": "mach-superstudio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "mach-superstudio.html#quarto",
    "href": "mach-superstudio.html#quarto",
    "title": "mach-superstudio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "notebooks/retreat_index.html",
    "href": "notebooks/retreat_index.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport colorcet as cc\nfrom matplotlib.colors import ListedColormap\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nimport pyarrow\n\n\nbase_path = '../data/'\n\n\ncluster_dat = gpd.read_file(base_path + 'clustering_data.geojson')\n\n\ncluster_dat.head()\n\n\n\n\n\n\n\n\ngeoid\npov_rt\nflood_risk\nnamelsad\nNAME\ntot_pop_1940\ntot_pop_1950\ntot_pop_1960\ntot_pop_1970\ntot_pop_1980\n...\ndeciduous_forest\nevergreen_forest\nmixed_forest\nshrub_scrub\ngrassland_herbaceous\npasture_hay\ncultivated_crops\nwoody_wetlands\nemergent_herbaceous_wetlands\ngeometry\n\n\n\n\n0\n3400100100\n0.406424\n0.693030\nAbsecon city\nAbsecon city, Atlantic County, New Jersey\n2084.0\n2355.0\n4320.0\n6094.0\n6859.0\n...\n0.015168\n0.001250\n0.028210\n0.000915\n0.001041\n0.002462\n0.003178\n0.080904\n0.251300\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n\n\n1\n3400102080\n0.775740\n0.971788\nAtlantic City city\nAtlantic City city, Atlantic County, New Jersey\n64094.0\n61657.0\n59544.0\n47859.0\n40199.0\n...\n0.000101\n0.000101\n0.000020\n0.000525\n0.000942\n0.000000\n0.000000\n0.014594\n0.311823\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n\n\n2\n3400107810\n0.302975\n0.966959\nBrigantine city\nBrigantine city, Atlantic County, New Jersey\n403.0\n1267.0\n4201.0\n6741.0\n8318.0\n...\n0.000928\n0.000000\n0.000192\n0.001503\n0.005833\n0.000000\n0.000832\n0.015162\n0.287935\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n\n\n3\n3400108680\n0.569470\n0.181154\nBuena borough\nBuena borough, Atlantic County, New Jersey\n3111.0\n2640.0\n3243.0\n3283.0\n3642.0\n...\n0.105284\n0.003854\n0.022989\n0.004221\n0.004542\n0.003341\n0.484193\n0.061991\n0.000315\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n\n\n4\n3400108710\n0.449822\n0.579928\nBuena Vista township\nBuena Vista township, Atlantic County, New Jersey\n4067.0\n2106.0\n3915.0\n4239.0\n6959.0\n...\n0.273240\n0.023212\n0.157290\n0.009062\n0.008720\n0.005383\n0.146850\n0.223212\n0.002444\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n\n\n\n\n5 rows Ã— 32 columns\n\n\n\n\ncluster_dat.columns\n\nIndex(['geoid', 'pov_rt', 'flood_risk', 'namelsad', 'NAME', 'tot_pop_1940',\n       'tot_pop_1950', 'tot_pop_1960', 'tot_pop_1970', 'tot_pop_1980',\n       'tot_pop_1990', 'tot_pop_2000', 'tot_pop_2010', 'tot_pop_2020',\n       'size_class', 'pct_res_vac', 'open_water', 'developed_open_space',\n       'developed_low_intensity', 'developed_medium_intensity',\n       'developed_high_intensity', 'barren_land_rock_sand_clay',\n       'deciduous_forest', 'evergreen_forest', 'mixed_forest', 'shrub_scrub',\n       'grassland_herbaceous', 'pasture_hay', 'cultivated_crops',\n       'woody_wetlands', 'emergent_herbaceous_wetlands', 'geometry'],\n      dtype='object')\n\n\n\ncluster_dat.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n# calculate the pct 70 year pop change from tot_pop_1950 and tot_pop_2020\ncluster_dat['pct_70_year_pop_change'] = ((cluster_dat['tot_pop_2020'] - cluster_dat['tot_pop_1950']) / cluster_dat['tot_pop_1950']) * 100\n\n\n# select the following columns: P200_I_PFS, FLD_PFS, pct_thirty_yr_pop_change, geometry\nretreat_index_gdf = cluster_dat[['pov_rt', 'flood_risk', 'pct_70_year_pop_change', 'developed_high_intensity', 'tot_pop_2020', 'geometry']]\n\n\nretreat_index_gdf.head()\n\n\n\n\n\n\n\n\npov_rt\nflood_risk\npct_70_year_pop_change\ndeveloped_high_intensity\ntot_pop_2020\ngeometry\n\n\n\n\n0\n0.406424\n0.693030\n287.983015\n0.024833\n9137.0\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n\n\n1\n0.775740\n0.971788\n-37.562645\n0.154158\n38497.0\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n\n\n2\n0.302975\n0.966959\n508.997632\n0.058109\n7716.0\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n\n\n3\n0.569470\n0.181154\n70.492424\n0.015367\n4501.0\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n\n\n4\n0.449822\n0.579928\n233.950617\n0.003296\n7033.0\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n\n\n\n\n\n\n\n\n# plot maps of each of the numeric cols in the retreat_index_gdf\nfig, ax = plt.subplots(3, 2, figsize=(14, 20))\nretreat_index_gdf.plot(column='pov_rt', cmap='viridis', ax=ax[0][0])\nax[0][0].set_title('Poverty')\nax[0][0].axis('off')\n\nretreat_index_gdf.plot(column='flood_risk', cmap='viridis', ax=ax[0][1])\nax[0][1].set_title('Flood Risk')\nax[0][1].axis('off')\n\nretreat_index_gdf.plot(column='pct_70_year_pop_change', cmap='viridis', ax=ax[1][0])\nax[1][0].set_title('Pop Change')\nax[1][0].axis('off')\n\nretreat_index_gdf.plot(column='developed_high_intensity', cmap='viridis', ax=ax[1][1])\nax[1][1].set_title('High Density (Industrial)')\nax[1][1].axis('off')\n\nretreat_index_gdf.plot(column='tot_pop_2020', cmap='viridis', ax=ax[2][0])\nax[2][0].set_title('Total Population 2020')\nax[2][0].axis('off')\n\nplt.show()\n\n\n\n\n\n# Exclude non-numeric columns\nnumeric_cols = retreat_index_gdf.select_dtypes(include=[np.number]).columns\n\n# Calculate correlation matrix\ncorr = retreat_index_gdf[numeric_cols].corr()\n\n# Plot correlation matrix\nplt.matshow(corr)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\nplt.yticks(range(len(corr.columns)), corr.columns)\nplt.colorbar()\n\n# Add correlation values\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center', color='w')\n\nplt.show()\n\n\n\n\n\n# Histograms for the four variables\nplt.figure(figsize=(20, 10))\n\n# Function to apply log transformation\ndef log_transform(column):\n    if (column &lt;= 0).any():\n        min_value = column.min()\n        shift_constant = np.abs(min_value) + 1\n        return np.log(column + shift_constant)\n    else:\n        return np.log(column)\n\n# Histogram for Poverty Index\nplt.subplot(2, 3, 1)\ntransformed_pov_rt = log_transform(retreat_index_gdf['pov_rt'])\nplt.hist(transformed_pov_rt, bins=20, color='skyblue', edgecolor='black')\nplt.xlabel('Transformed Poverty Index')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Poverty Index')\n\n# Histogram for Flood Risk\nplt.subplot(2, 3, 2)\nplt.hist(retreat_index_gdf['flood_risk'], bins=20, color='lightgreen', edgecolor='black')\nplt.xlabel('Flood Risk')\nplt.ylabel('Frequency')\nplt.title('Distribution of Flood Risk')\n\n# Histogram for Population Change\nplt.subplot(2, 3, 3)\ntransformed_pop_change = log_transform(retreat_index_gdf['pct_70_year_pop_change'])\nplt.hist(transformed_pop_change, bins=20, color='salmon', edgecolor='black')\nplt.xlabel('Transformed Population Change')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Population Change')\n\n# Histogram for Developed High Intensity\nplt.subplot(2, 3, 4)\ntransformed_developed_high_intensity = np.sqrt(retreat_index_gdf['developed_high_intensity'])\nplt.hist(transformed_developed_high_intensity, bins=20, color='purple', edgecolor='black')\nplt.xlabel('Square Root Transformed Developed High Intensity')\nplt.ylabel('Frequency')\nplt.title('Distribution of Square Root Transformed Developed High Intensity')\n\n\n# Histogram for Total Population\nplt.subplot(2, 3, 5)\ntransformed_tot_pop_2020 = log_transform(retreat_index_gdf['tot_pop_2020'])\nplt.hist(transformed_tot_pop_2020, bins=20, color='orange', edgecolor='black')\nplt.xlabel('Transformed Total Population 2020')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Total Population 2020')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Step 1: Apply transformations\nretreat_index_gdf['log_pov_rt'] = np.log(retreat_index_gdf['pov_rt'])\nretreat_index_gdf['log_tot_pop_2020'] = np.log(retreat_index_gdf['tot_pop_2020'])\nretreat_index_gdf['sqrt_flood_risk'] = np.sqrt(retreat_index_gdf['flood_risk'])\nretreat_index_gdf['squared_developed_high_intensity'] = retreat_index_gdf['developed_high_intensity'] ** 2\n\n# Step 2: Z-score normalize the variables\nscaler = StandardScaler()\nvariables_to_normalize = ['log_pov_rt', 'sqrt_flood_risk', 'pct_70_year_pop_change', 'squared_developed_high_intensity', 'log_tot_pop_2020']\n# Drop NA values from the dataframe to avoid errors in scaling and clustering\ncleaned_gdf = retreat_index_gdf.dropna(subset=variables_to_normalize)\nnormalized_data = scaler.fit_transform(cleaned_gdf[variables_to_normalize])\nnormalized_df = pd.DataFrame(normalized_data, columns=variables_to_normalize, index=cleaned_gdf.index)\n\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n# run PCA on the normalized data to show which variables are most important\nfrom sklearn.decomposition import PCA\n\npca = PCA()\npca.fit(normalized_df)\n\n# Plot the explained variance ratio\nplt.figure(figsize=(10, 6))\n\nplt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o')\nplt.xlabel('Principal Component')\nplt.ylabel('Explained Variance Ratio')\n\nplt.show()\n\n\n\n\n\n# show the eigenvalues of each componnet\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(range(1, len(pca.explained_variance_) + 1), pca.explained_variance_, marker='o')\nplt.xlabel('Principal Component')\nplt.ylabel('Eigenvalue')\n\nplt.show()\n\n\n\n\n\n# show which variables are most important in each component\n# Create a DataFrame with the loadings\n\nloadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i}' for i in range(1, len(pca.components_) + 1)], index=variables_to_normalize)\n\n# Plot the loadings\nplt.figure(figsize=(10, 6))\n\nplt.barh(loadings.index, loadings['PC1'])\nplt.xlabel('Loading Value')\nplt.ylabel('Variable')\n\nplt.show()\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Step 1: Compute WCSS for different numbers of clusters\nwcss = []  # List to store WCSS values\ncluster_range = range(1, 11)  # Adjust the range as needed\n\nfor n_clusters in cluster_range:\n    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=42)\n    kmeans.fit(normalized_df)  # Assuming 'normalized_df' is your pre-processed data\n    wcss.append(kmeans.inertia_)  # inertia_ is the WCSS\n\n# Step 2: Plot the elbow plot\nplt.figure(figsize=(10, 6))\nplt.plot(cluster_range, wcss, marker='o', linestyle='-', color='blue')\nplt.title('Elbow Method For Optimal Number of Clusters')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.xticks(cluster_range)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n# Step 3: Cluster the normalized and cleaned data\nkmeans = KMeans(n_clusters=7, random_state=42)  # Adjust the number of clusters as needed\nclusters = kmeans.fit_predict(normalized_df)\n\n\ncleaned_gdf['cluster'] = clusters  # Add cluster labels to the cleaned GeoDataFrame\n\n\n# Step 4: Map the clusters\n# Ensure the GeoDataFrame for plotting includes the cluster information\nretreat_index_gdf = retreat_index_gdf.merge(cleaned_gdf[['cluster']], left_index=True, right_index=True, how='left')\n\n\nretreat_index_gdf.head()\n\n\n\n\n\n\n\n\npov_rt\nflood_risk\npct_70_year_pop_change\ndeveloped_high_intensity\ntot_pop_2020\ngeometry\nlog_pov_rt\nlog_tot_pop_2020\nsqrt_flood_risk\nsquared_developed_high_intensity\ncluster\n\n\n\n\n0\n0.406424\n0.693030\n287.983015\n0.024833\n9137.0\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n-0.900360\n9.120087\n0.832484\n0.000617\n2\n\n\n1\n0.775740\n0.971788\n-37.562645\n0.154158\n38497.0\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n-0.253938\n10.558336\n0.985793\n0.023765\n2\n\n\n2\n0.302975\n0.966959\n508.997632\n0.058109\n7716.0\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n-1.194105\n8.951051\n0.983341\n0.003377\n2\n\n\n3\n0.569470\n0.181154\n70.492424\n0.015367\n4501.0\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n-0.563049\n8.412055\n0.425622\n0.000236\n5\n\n\n4\n0.449822\n0.579928\n233.950617\n0.003296\n7033.0\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n-0.798903\n8.858369\n0.761530\n0.000011\n5\n\n\n\n\n\n\n\n\nretreat_index_gdf.columns\n\nIndex(['pov_rt', 'flood_risk', 'pct_70_year_pop_change',\n       'developed_high_intensity', 'tot_pop_2020', 'geometry', 'log_pov_rt',\n       'log_tot_pop_2020', 'sqrt_flood_risk',\n       'squared_developed_high_intensity', 'cluster'],\n      dtype='object')\n\n\n\n# Select a colorcet palette and create a ListedColormap\ncolors = cc.glasbey_hv[:6]  # For 7 clusters\ncmap = ListedColormap(colors)\n\n# Plotting\nfig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size\nretreat_index_gdf.plot(column='cluster', cmap=cmap, legend=True, ax=ax, categorical=True)\n\n# Adjusting the legend to be outside\nlegend = ax.get_legend()\nif legend:\n    legend.set_bbox_to_anchor((1.2, 1))  # Move the legend further right\n    legend.set_title('Cluster')\n    legend.set_frame_on(False)  # Remove the frame of the legend\n\n# Remove the frame, ticks, and labels\nax.set_frame_on(False)\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the layout to leave space for the legend\nplt.show()\n\n\n\n\n\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Step 1: Apply PCA for 3 components\npca = PCA(n_components=3)\npca_data = pca.fit_transform(normalized_df)\n\n# Step 2: Create a DataFrame with the PCA data\npca_df = pd.DataFrame(pca_data, columns=['PC1', 'PC2', 'PC3'], index=cleaned_gdf.index)\n\n# Step 3: Merge the PCA data with the cluster labels\npca_df = pca_df.merge(cleaned_gdf[['cluster']], left_index=True, right_index=True, how='left')\n\n# Step 4: Plot the clusters in 3D, with custom colors\nfig = plt.figure(figsize=(12, 14))\nax = fig.add_subplot(111, projection='3d')\n\n# Define a color list, changing the color for cluster 5\ncolors = ['blue', 'green', 'red', 'magenta', 'purple', 'gold', 'orange', 'lightblue']\n\n# Sort the clusters\nsorted_clusters = sorted(pca_df['cluster'].unique())\n\nfor cluster in sorted_clusters:\n    cluster_data = pca_df[pca_df['cluster'] == cluster]\n    # Use modulo to avoid index errors if there are more clusters than colors\n    color = colors[cluster % len(colors)]\n    ax.scatter(cluster_data['PC1'], cluster_data['PC2'], cluster_data['PC3'], label=f'Cluster {cluster}', color=color, alpha=0.7)\n    \nax.set_xlabel('Principal Component 1')\nax.set_ylabel('Principal Component 2')\nax.set_zlabel('Principal Component 3')\nax.set_title('3D Clusters in PCA Space')\nax.legend()\n\n# Adjust layout to prevent clipping\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n# Variables to plot\nvariables = ['pov_rt', 'flood_risk', 'pct_70_year_pop_change', 'developed_high_intensity', 'log_tot_pop_2020']\ntitles = ['Poverty Index', 'Flood Risk', 'Population Change', 'High Industry', 'Tot Pop 2020']\n\n# Creating box plots\nfig, axes = plt.subplots(3, 2, figsize=(10, 10))\n\n# Flatten the axes array and iterate over it\nfor ax, var, title in zip(axes.flatten(), variables, titles):\n\n    # Prepare data for plotting: extract values for each cluster\n    data_to_plot = [retreat_index_gdf[retreat_index_gdf['cluster'] == cluster][var] for cluster in sorted(retreat_index_gdf['cluster'].unique())]\n    \n    # Create box plot\n    ax.boxplot(data_to_plot)\n    \n    # Setting titles and labels\n    ax.set_title(title)\n    ax.set_xlabel('Cluster')\n    ax.set_ylabel('Value')\n    ax.set_xticklabels(sorted(retreat_index_gdf['cluster'].unique()))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Create a new column 'highlight' that is True for clusters 2 and 3, and False otherwise\nretreat_index_gdf['highlight'] = retreat_index_gdf['cluster'].isin([1, 2])\n\n# Create a color map for the highlight: use bright colors for True (clusters 2 and 3) and a dull color for False\nhighlight_cmap = ListedColormap(['#aaaaaa', '#ff0000', 'orange'])\n\n# Plotting\nfig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size\nretreat_index_gdf.plot(column='highlight', cmap=highlight_cmap, legend=True, ax=ax, categorical=True)\n\n# Adjusting the legend to be outside\nlegend = ax.get_legend()\nif legend:\n    legend.set_bbox_to_anchor((1.2, 1))  # Move the legend further right\n    legend.set_title('Legacy Cities with Climate Impacts')\n    legend.set_frame_on(False)  # Remove the frame of the legend\n\n# Remove the frame, ticks, and labels\nax.set_frame_on(False)\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the layout to leave space for the legend\nplt.show()\n\n\n\n\n\n# read the nj_cest from a geoparquet file\nnj_cejst = gpd.read_parquet(base_path + 'nj_cejst.parquet')\n\n\nnj_cejst.head()\n\n\n\n\n\n\n\n\nGEOID10\nSF\nCF\nDF_PFS\nAF_PFS\nHDF_PFS\nDSF_PFS\nEBF_PFS\nEALR_PFS\nEBLR_PFS\n...\nAGE_10\nAGE_MIDDLE\nAGE_OLD\nTA_COU_116\nTA_COUNT_C\nTA_PERC\nTA_PERC_FE\nUI_EXP\nTHRHLD\ngeometry\n\n\n\n\n40677\n34015501210\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.43\n0.38\n0.30\n0.36\n...\n0.12\n0.73\n0.13\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.08790 39.71565, -75.08840 39.715...\n\n\n40678\n34015501301\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.54\n0.44\n0.20\n0.36\n...\n0.07\n0.76\n0.16\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.11347 39.73927, -75.11351 39.739...\n\n\n40679\n34015501303\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.54\n0.61\n0.34\n0.39\n...\n0.08\n0.66\n0.24\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.13190 39.72464, -75.13088 39.723...\n\n\n40680\n34015501900\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.40\n0.63\n0.67\n0.39\n...\n0.07\n0.76\n0.16\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.19511 39.66308, -75.19538 39.663...\n\n\n40681\n34015500300\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.80\n0.57\n0.50\n0.74\n...\n0.10\n0.76\n0.13\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.19502 39.87752, -75.19471 39.877...\n\n\n\n\n5 rows Ã— 124 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap\n\n# Assuming retreat_index_gdf and nj_cest are previously defined GeoDataFrames\n\n# Modify the highlight column to differentiate clusters 1 and 2\nretreat_index_gdf['highlight'] = retreat_index_gdf['cluster'].apply(lambda x: 0 if x not in [1, 2] else (1 if x == 1 else 2))\n\n# Generate colors for the highlight - pick from viridis\nviridis = plt.cm.get_cmap('viridis', 3)  # Get 3 distinct colors from viridis\nhighlight_colors = [viridis.colors[0], viridis.colors[1], viridis.colors[2]]  # Pick colors for clusters 1, 2, and others\nhighlight_cmap = ListedColormap(highlight_colors)\n\n# Set up a figure with two columns and 5 rows (since you'll have 9 plots)\nfig, ax = plt.subplots(4, 2, figsize=(14, 35))  # Adjust size as needed\n\n# Flatten the ax for easy indexing\nax = ax.flatten()\n\n# Define a new colormap for your first plot if needed\nviridis_half = plt.cm.viridis(np.linspace(0, 0.5, 256))\nnewcmp = LinearSegmentedColormap.from_list('HalfViridis', viridis_half)\n\n# Plotting with the custom colormap for 'highlight'\nretreat_index_gdf.plot(column='highlight', cmap=highlight_cmap, ax=ax[0], categorical=True)\nax[0].set_title('Legacy Cities x Climate Index')\nax[0].axis('off')\n\n# Add other plots as before, adjusting ax indexing\n# Example for the second plot\nnj_cejst.plot(column='TC', cmap='viridis', ax=ax[1])\nax[1].set_title('New Jersey CEJST')\nax[1].axis('off')\n\n# Plot for 'pov_rt' (3x3 position: 1,3)\nretreat_index_gdf.plot(column='pov_rt', cmap='viridis', ax=ax[2])\nax[2].set_title('Poverty')\nax[2].axis('off')  # Remove axes and ticks\n\n# Plot for 'flood_risk' (3x3 position: 2,1)\nretreat_index_gdf.plot(column='flood_risk', cmap='viridis', ax=ax[3])\nax[3].set_title('Flood Risk')\nax[3].axis('off')  # Remove axes and ticks\n\n# Plot for 'pct_70_year_pop_change' (3x3 position: 2,2)\nretreat_index_gdf.plot(column='pct_70_year_pop_change', cmap='viridis', ax=ax[4])\nax[4].set_title('Pop Change')\nax[4].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'developed_high_intensity' (3x3 position: 2,3)\nretreat_index_gdf.plot(column='developed_high_intensity', cmap='viridis', ax=ax[5])\nax[5].set_title('High Density (Industrial)')\nax[5].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'tot_pop_2020' (3x3 position: 3,1)\nretreat_index_gdf.plot(column='tot_pop_2020', cmap='viridis', ax=ax[6])\nax[6].set_title('Total Population 2020')\nax[6].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'pct_res_vac' (3x3 position: 3,2)\ncluster_dat.plot(column='pct_res_vac', cmap='viridis', ax=ax[7])\nax[7].set_title('Pct. Residential Vacancy')\nax[7].axis('off')  # Remove axes and ticks\n\n# Adjust layout and show figure\nplt.tight_layout()\nplt.show()\n\nC:\\Users\\Nissim\\AppData\\Local\\Temp\\ipykernel_26408\\1970897904.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  viridis = plt.cm.get_cmap('viridis', 3)  # Get 3 distinct colors from viridis\n\n\n\n\n\n\n# add a histogram showing the total population of each municipality in the 'highlight' column\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Filter DataFrame for rows where 'highlight' is True, apply log transformation to 'tot_pop_2020', and plot histogram\nnp.log1p(retreat_index_gdf[retreat_index_gdf['highlight']]['tot_pop_2020']).plot.hist(ax=ax, bins=30, color='orange', edgecolor='black')\nplt.xlabel('Log-transformed Total Population')\nplt.ylabel('Frequency')\nplt.title('Log-transformed Total Population of Legacy Cities with Climate Impacts')\n\nplt.show()\n\n\n\n\n\n# print out a list of the municipalities in the highlight column where the log-transformed total population is within 2 standard deviations of the mean\n# Calculate the mean and standard deviation of the log-transformed total population\nmean_log_pop = np.log1p(retreat_index_gdf['tot_pop_2020']).mean()\nstd_log_pop = np.log1p(retreat_index_gdf['tot_pop_2020']).std()\n\n# Filter the DataFrame for rows where 'highlight' is True and the log-transformed total population is within 2 standard deviations of the mean\nhighlighted_municipalities = retreat_index_gdf[(retreat_index_gdf['highlight']) & (np.log1p(retreat_index_gdf['tot_pop_2020']) &gt;= mean_log_pop - 2 * std_log_pop) & (np.log1p(retreat_index_gdf['tot_pop_2020']) &lt;= mean_log_pop + 2 * std_log_pop)]\n\n\n# plot the highlighted municipalities on a map\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Plot the base map\nnj_cejst.plot(ax=ax, color='lightgrey', edgecolor='black', linewidth=0.1)\n\n# Plot the highlighted municipalities\nhighlighted_municipalities.plot(ax=ax, color='pink', edgecolor='black', linewidth=0.5)\n\n# Add a title\n\nplt.title('Highlighted Municipalities with Total Population within 2 Standard Deviations of the Mean')\n\n# Remove the axis\nax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "scratch/gee_raster_data.html",
    "href": "scratch/gee_raster_data.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "import ee\nimport geemap\nimport geopandas as gpd\nimport pygris\nfrom pygris import states\nimport rasterio\nimport fiona\n\n\n# ee.Authenticate()\nee.Initialize(project='hotspotstoplight')\n\n\n            \n            \n\n\nTo authorize access needed by Earth Engine, open the following\n        URL in a web browser and follow the instructions:\n        https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=23lWhyvJb_0H9ODqEadyJyaJ54aAZOx9-Iww00OuC4k&tc=TrfrhhGv7I4TuFL127PDhXDF5ijTZAceQT24GK7SOb4&cc=-l57KD7iq9DfNgLPG12iy3GAt4uaXWgs4Mn1M-2Fm_w\n        The authorization workflow will generate a code, which you should paste in the box below.\n        \n\n\n\nSuccessfully saved authorization token.\n\n\n\nus = states(cb = True, resolution = \"20m\")\nnj = us[us['NAME'] == 'New Jersey']\nnj_ee = geemap.geopandas_to_ee(nj)\n\n# Create a Map\nMap = geemap.Map()\n\nMap.addLayerControl()\n\n# Filter the NLCD Tree Canopy Cover (TCC) for 2021 and CONUS\ndataset = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/TCC/v2021-4')\ntcc = dataset.filter(ee.Filter.calendarRange(2021, 2021, 'year')) \\\n             .filter(ee.Filter.eq('study_area', 'CONUS')) \\\n             .first() \\\n             .clip(nj_ee)  # Clip to NJ boundaries\n\n# Add TCC layer\nMap.addLayer(tcc.select('NLCD_Percent_Tree_Canopy_Cover'), {'min': 0, 'max': 60, 'palette': tcc_palette}, 'NLCD Percent Tree Canopy Cover')\n\n# World Settlement Footprint (WSF) 2015 clipped to NJ\nwsf_dataset = ee.Image('DLR/WSF/WSF2015/v1').clip(nj_ee)\nMap.addLayer(wsf_dataset, wsf_vis, 'Human settlement areas')\n\n# Population Density clipped to NJ\npopulation_dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Population_Density').first().clip(nj_ee)\nMap.addLayer(population_dataset, population_vis, 'Population Density')\n\n# Global Tidal Wetland Change 2019 clipped to NJ\ntidal_dataset = ee.Image('JCU/Murray/GIC/global_tidal_wetland_change/2019').clip(nj_ee)\nMap.addLayer(tidal_dataset.select('loss'), {'palette': loss_palette, 'min': 1, 'max': 1}, 'Tidal Wetland Loss')\nMap.addLayer(tidal_dataset.select('gain'), {'palette': gain_palette, 'min': 1, 'max': 1}, 'Tidal Wetland Gain')\n\n# Bio-Intactness Dataset clipped to NJ\nbdi_ic = ee.ImageCollection(\"projects/ebx-data/assets/earthblox/IO/BIOINTACT\").mean().clip(nj_ee)\nMap.addLayer(bdi_ic, bdi_vis, \"Bio-Intactness\")\n\n# Biodiversity, Carbon, and Water datasets clipped to NJ\nbiodiv_biome_clipped = biodiv_biome.clip(nj_ee)\nbiodivcarbon_clipped = biodivcarbon.clip(nj_ee)\nbiodivcarbonwater_clipped = biodivcarbonwater.clip(nj_ee)\n\n# Add Biodiversity and Carbon layers\nMap.addLayer(biodivcarbon_clipped, biodiv_carbon_vis, \"Biodiversity and Carbon\")\nMap.addLayer(biodivcarbonwater_clipped, biodiv_carbon_vis, \"Biodiversity, Carbon, and Water\")\n\n# Global Forest Change dataset clipped to NJ\ngfc_dataset = ee.Image('UMD/hansen/global_forest_change_2022_v1_10').clip(nj_ee)\nMap.addLayer(gfc_dataset, treeCoverVisParam, 'Tree Cover')\nMap.addLayer(gfc_dataset, treeLossVisParam, 'Tree Loss Year')\n\n# Set the map center to New Jersey with an appropriate zoom level\nMap.setCenter(-74.4057, 40.0583, 7)  # Longitude, Latitude, Zoom Level\n\n# Show the map\nMap\n\n\n            \n            \n\n\n\ndef export_to_drive(image, description, folder, region, scale=250):\n    task = ee.batch.Export.image.toDrive(\n        image=image,\n        description=description,\n        folder=folder,\n        scale=scale,\n        region=region.geometry().bounds().getInfo()['coordinates'],\n        fileFormat='GeoTIFF'\n    )\n    task.start()\n\n# Assuming 'nj_ee' is your Earth Engine geometry for New Jersey\n# Assuming each dataset is clipped to 'nj_ee' and ready for export\n\n# Dictionary of datasets and their names for export\ndatasets = {\n    'TCC_NJ': tcc.select('NLCD_Percent_Tree_Canopy_Cover'),\n    'WSF2015_NJ': wsf_dataset,\n    'PopulationDensity_NJ': population_dataset,\n    'TidalWetlandChange2019_NJ': tidal_dataset,\n    # Add more datasets here as needed\n}\n\n# Folder name in Google Drive\nfolder_name = \"MACH Studio Data\"\n\n# Iterate over the datasets dictionary and export each\nfor description, image in datasets.items():\n    export_to_drive(image, description, folder_name, nj_ee)\n\nprint(\"Export tasks started. Check the 'Tasks' tab in the Google Earth Engine Code Editor for progress.\")"
  },
  {
    "objectID": "SETUP.html",
    "href": "SETUP.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow these steps to set up the project environment:\n\n\nFollow the instructions at https://github.com/pypa/pipx to install pipx.\n\n\n\nFollow the instructions at https://github.com/pyenv/pyenv to install pyenv.\n\n\n\nVisit https://python-poetry.org/docs/ for instructions on installing Poetry.\n\n\n\nClone the git repository to your local machine by running the following command in your command line interface (CLI):\ngit clone git@github.com:nlebovits/mach-superstudio.git\n\n\n\nIn your command line interface (CLI), navigate to /mach-superstudio and then run poetry install.\n\n\n\nExecute the following to create a virtual environment in the project directory:\npoetry config virtualenvs.in-project true\n\n\n\nActivate the virtual environment by running:\npoetry shell\nIf using VS Code, you might need to specify the path to the virtual environment. Run the following command to get the path:\npoetry env info --path\nCopy the output path and paste it into VS Codeâ€™s Python interpreter path setting. You should now be ready to run the scripts in VS Code."
  },
  {
    "objectID": "SETUP.html#install-pipx",
    "href": "SETUP.html#install-pipx",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow the instructions at https://github.com/pypa/pipx to install pipx."
  },
  {
    "objectID": "SETUP.html#install-pyenv",
    "href": "SETUP.html#install-pyenv",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow the instructions at https://github.com/pyenv/pyenv to install pyenv."
  },
  {
    "objectID": "SETUP.html#install-poetry",
    "href": "SETUP.html#install-poetry",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Visit https://python-poetry.org/docs/ for instructions on installing Poetry."
  },
  {
    "objectID": "SETUP.html#clone-the-github-repository",
    "href": "SETUP.html#clone-the-github-repository",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Clone the git repository to your local machine by running the following command in your command line interface (CLI):\ngit clone git@github.com:nlebovits/mach-superstudio.git"
  },
  {
    "objectID": "SETUP.html#install-dependencies-with-poetry",
    "href": "SETUP.html#install-dependencies-with-poetry",
    "title": "Mach Superstudio",
    "section": "",
    "text": "In your command line interface (CLI), navigate to /mach-superstudio and then run poetry install."
  },
  {
    "objectID": "SETUP.html#configure-poetry-virtual-environment",
    "href": "SETUP.html#configure-poetry-virtual-environment",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Execute the following to create a virtual environment in the project directory:\npoetry config virtualenvs.in-project true"
  },
  {
    "objectID": "SETUP.html#activate-the-virtual-environment",
    "href": "SETUP.html#activate-the-virtual-environment",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Activate the virtual environment by running:\npoetry shell\nIf using VS Code, you might need to specify the path to the virtual environment. Run the following command to get the path:\npoetry env info --path\nCopy the output path and paste it into VS Codeâ€™s Python interpreter path setting. You should now be ready to run the scripts in VS Code."
  }
]