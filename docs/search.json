[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MACH Superstudio Clustering",
    "section": "",
    "text": "Climate adaptation funding is crucial for coastal regions in the United States, particularly as these areas confront escalating threats like sea-level rise, routine flooding, intensified storm surges, and an increased frequency of extreme weather events. These environmental challenges threaten infrastructure, ecosystems, and human livelihoods, underscoring the urgent need for effective climate adaptation strategies. Despite the necessity of this funding, it is often unevenly distributed, generally favoring larger, more populous areas capable of leveraging greater adaptive capacity. This trend results in smaller, economically distressed communities in New Jersey being disproportionately vulnerable, as they receive less climate adaptation funding compared to their larger counterparts.\nTo address this inequity, new tools such as the Federal government’s Climate and Economic Justice Screening Tool (CEJST) aim to direct adaptation funding toward the most vulnerable communities. However, these efforts often simplify vulnerability on a single axis, overlooking the complex realities of various places experiencing climate vulnerability. Our report highlights a specific group of overlooked places in New Jersey—smaller, declining areas with significant climate risks, using Salem and Atlantic City as case studies. These cities face unique challenges such as limited adaptive capacity, population decline, budget constraints, legacy infrastructure issues, scale mismatch, and high flood risks. By employing a k-means clustering method, we identify locales across New Jersey with shared vulnerabilities, allowing for a targeted and effective approach to climate adaptation.\nOur recommendations emphasize the need for a nuanced funding approach that accounts for the unique vulnerabilities of smaller communities, not merely their statistical risk levels. We propose integrating our findings with existing statewide climate adaptation initiatives to foster collaboration and reduce redundancy, enhancing the overall impact of adaptation strategies. Additionally, we advocate for filling data gaps with finer-scale, high-resolution data collection and engaging directly with vulnerable communities to validate and refine our models. This will ensure that our strategies are grounded in reality and effectively meet the specific needs of these communities.\nOur approach aims to encourage the provision smaller towns in New Jersey with the necessary tools and resources to not only survive but thrive in the face of growing climate challenges. By focusing on these often-neglected areas, leveraging detailed, location-specific data, and fostering state-wide partnerships, we can ensure a comprehensive and equitable climate adaptation strategy that benefits the entire state, enhancing resilience and sustainability for all residents."
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "MACH Superstudio Clustering",
    "section": "",
    "text": "Climate adaptation funding is crucial for coastal regions in the United States, particularly as these areas confront escalating threats like sea-level rise, routine flooding, intensified storm surges, and an increased frequency of extreme weather events. These environmental challenges threaten infrastructure, ecosystems, and human livelihoods, underscoring the urgent need for effective climate adaptation strategies. Despite the necessity of this funding, it is often unevenly distributed, generally favoring larger, more populous areas capable of leveraging greater adaptive capacity. This trend results in smaller, economically distressed communities in New Jersey being disproportionately vulnerable, as they receive less climate adaptation funding compared to their larger counterparts.\nTo address this inequity, new tools such as the Federal government’s Climate and Economic Justice Screening Tool (CEJST) aim to direct adaptation funding toward the most vulnerable communities. However, these efforts often simplify vulnerability on a single axis, overlooking the complex realities of various places experiencing climate vulnerability. Our report highlights a specific group of overlooked places in New Jersey—smaller, declining areas with significant climate risks, using Salem and Atlantic City as case studies. These cities face unique challenges such as limited adaptive capacity, population decline, budget constraints, legacy infrastructure issues, scale mismatch, and high flood risks. By employing a k-means clustering method, we identify locales across New Jersey with shared vulnerabilities, allowing for a targeted and effective approach to climate adaptation.\nOur recommendations emphasize the need for a nuanced funding approach that accounts for the unique vulnerabilities of smaller communities, not merely their statistical risk levels. We propose integrating our findings with existing statewide climate adaptation initiatives to foster collaboration and reduce redundancy, enhancing the overall impact of adaptation strategies. Additionally, we advocate for filling data gaps with finer-scale, high-resolution data collection and engaging directly with vulnerable communities to validate and refine our models. This will ensure that our strategies are grounded in reality and effectively meet the specific needs of these communities.\nOur approach aims to encourage the provision smaller towns in New Jersey with the necessary tools and resources to not only survive but thrive in the face of growing climate challenges. By focusing on these often-neglected areas, leveraging detailed, location-specific data, and fostering state-wide partnerships, we can ensure a comprehensive and equitable climate adaptation strategy that benefits the entire state, enhancing resilience and sustainability for all residents."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "MACH Superstudio Clustering",
    "section": "2 Introduction",
    "text": "2 Introduction\n\n2.1 Adaptation Funding\nFunding is critical for coastal climate adaptation in the United States due to the escalating threats posed by sea-level rise, routine flooding, intensified storm surges, and increased frequency of extreme weather events. Coastal regions are experiencing severe impacts that jeopardize infrastructure, ecosystems, and human livelihoods. Funding climate adaptation involves directing financial resources towards initiatives that enable communities to minimize the risks and potential damages from climate hazards such as storms or droughts. Adequate funding supports the development and implementation of resilience strategies, such as enhancing coastal barriers, restoring wetlands, and improving emergency response systems. Investing in adaptation measures not only mitigates the adverse effects of climate change but also safeguards public health and safety, preserves local economies dependent on coastal resources, and ensures the long-term viability of these areas against future climate-related challenges.\nAround the world, climate adaptation funding is notoriously difficult to track, due partially to the lack of clarity surrounding terms like “adaptation,” and also due to the lack of a centralized system to track and account for adaptation funds, whether in the public or private sector. Even in the United States, there is no uniform, centralized repository to understand the flows of climate adaptation finance. As a result, it is difficult to speak empirically about which communities do and don’t receive climate adaptation funding in the United States.\nYet at a broad level, there is consensus among researchers and practitioners that climate adaptation funding is only infrequently a response to community vulnerability (Grecksch and Klock 2020). Although places with higher rates of climate exposure tend to be more likely to receive more aid, various studies have found that “available finance is not reaching those most vulnerable to climate impacts and who often have the fewest resources with which to adapt” (WRI “Adaptation Finance explained”). Internationally, the countries and communities with the most need receive comparably limited funding. Rather, funding is distributed on the basis of donor utility (in the case of the private sector) and the capacity of the recipient to absorb and use capital. This creates a dynamic in which places with the least adaptive capacity receive the least aid, regardless of their need (Barrett 2014; Weiler et al. 2018).\nAs in the rest of the world, this trend appears to hold true in New Jersey. While there is limited empirical analysis available for where adaptation funding goes in the state, some proxies are available. For example, the New Jersey Department of Environmental Protection (NJDEP) reports on climate investments made by the NJDEP, New Jersey Board of Public Utilities, and New Jersey Economic Development Authority using funds gained through the Regional Greenhouse Gas Initiative (RGGI). Per these data, it is apparent that money primarily goes to larger places in the state.\n\n\n\n\n\n\n\nAlthough there is no perfect proxy for adaptive capacity, larger places generally demonstrate greater capacity due to several inherent advantages. Urban areas, with their larger populations, typically benefit from more robust hard anbd soft infrastructure, including physical structures like roads and emergency services, and large bureaucratic and governmental apparati. These features contribute to a higher resilience against various challenges, including those posed by climate change. Moreover, larger cities often have access to more substantial budgets and greater political influence, which can facilitate quicker mobilization of resources and more effective implementation of adaptive strategies. This is supported by the presence of diverse industries and a larger tax base, which together enhance the economic stability necessary for sustained adaptation efforts.\n\n\n\n\n\n\n\n2.2 Identifying Vulnerable Places\nGiven the limited availability of climate adaptation funding compared to what is needed, there is a logic to this dynamic. It makes sense to try to maximize return on investment by focusing on places with large populations and enough adaptive capacity to take full advantage of funding. Yet the result of this logic is that smaller places—including many of the poorest places in New Jersey—are likely to be overlooked in the allocation of climate adaptation funding.\nIncreasingly, funders of climate adaptation recognize the need to direct resources to the most vulnerable places. At the level of the Federal government, the United States has now committed to directing resources to the most marginalized places. Under the Justice40 initiative, launched in 2023:\n\nthe Federal government has made it a goal that 40 percent of the overall benefits of certain Federal climate, clean energy, affordable and sustainable housing, and other investments flow to disadvantaged communities that are marginalized by underinvestment and overburdened by pollution.\n\nThis is an enormous investment in supporting climate adaptation in places that need it most. Yet the question remains of how these vulnerable places are identified—and what blind spots that might still entail.\nVarious tools have been proposed to identify vulnerable places. In 2003, Cutter et al. created the first social vulnerability index (SoVI), which sought to create a national-scale index of social vulnerability to environmental hazards. The tool was meant to be used to create a scalable way of comparing vulnerability between places at a national level in order to better direct various forms of support, whether monetary, practical, or otherwise.\nMore recently, in tandem with the Justice40 initiative, the Federal government launched the Climate and Economic Justice Screening Tool (CEJST), which seeks to identify “overburdened and underserved communities” facing challenges related to climate, energy, health, housing, legacy pollution, transportation, water and wastewater, and workforce development. CEJST ties explicitly into the context of climate adaptation funding because it is intended to be used to develop “40% of the overall benefits of investments in climate, clean energy, and related areas” to these communities (https://screeningtool.geoplatform.gov/en/about).\n\n\n\n\n\nOther comparable tools include the Center for Disease Control’s Social Vulnerability Index (SVI, distinct from Cutter’s SoVI), the Environmental Protection Agency’s EJScreen, the Environmental Defense Fund’s Climate Vulnerability Index, and more. In short, there is an increasing proliferation of tools meant to identify the “most vulnerable” places and direct resources and support to them. Yet, in thinking of vulnerability as a phenomenon that merely runs from least to most, these tools risk overlooking the different ways in which vulnerability manifests in different types of places.\n\n\n2.3 A Different Framework\nTools like the SoVI and CEJST are important steps toward more equitable, strategic distribution of funding and other resources to communities that miss it most. Yet, much like existing adaptation funding, these tools take too narrow an approach to vulnerability. As indices, they conceptualize vulnerability as something running from high to low, on a single axis. But as Spielman et al. (2020) write, “vulnerability is not a variable like temperature that runs from hot to cold, but something that manifests itself in many different forms in many different places.” Vulnerable places take different forms, having different needs and potential solutions. Failing to acknowledge the different types of vulnerable places can result in significant oversights. For example, in 2018, researchers at Rutgers University found that “the most economically distressed municipalities in South Jersey receive nearly one third less state aid than similarly impoverished cities and towns in Central and North Jersey” (ttps://whyy.org/articles/study-finds-state-aid-weighted-against-south-jerseys-poorest-cities/). Likewise, climate vulnerability takes decidedly different forms across the state of New Jersey. In the north, for example, cities on the Passaic River face routine riparian flooding, yet no risk from sea level rise. Meanwhile, southern coastal cities like Atlantic City face a high risk from storm surges and issues with coastal erosion. Although both places are vulnerable, they face decidedly different hazards, requiring different interventions.\nIn considering the geography of climate adaptation in coastal New Jersey, our focus shifts beyond just identifying areas of vulnerability to understanding their unique contexts and needs. This approach recognizes that vulnerability does not manifest uniformly; each locale, from larger urban centers like Newark and Camden to smaller towns like Salem, presents distinct challenges that demand tailored solutions. In the course of this research, we sought to identify particular types of vulnerable places, understand the driving factors that make them vulnerable, and derive insights that can be scaled to comparable places.\nOur research methodology involved an initial assessment using tools such as the CEJST, complemented by a thorough literature review aimed at identifying not only the common challenges these diverse locations face but also exploring potential shared solutions that could be adapted to local conditions. Through this process, we discovered recurring themes among smaller, legacy cities in New Jersey, which include economic distress, underfunded infrastructure projects, and a lack of comprehensive local planning initiatives tailored to specific climate risks. Addressing these issues requires an innovative approach to resource distribution and policy-making that takes into account the nuanced differences in vulnerability and capacity across the state. This nuanced understanding allows for more effective and equitable climate adaptation strategies, ensuring that all communities, regardless of size or economic status, are prepared to meet their unique environmental challenges head-on.\nThis semester, we focused on Salem City, New Jersey, as a prototypical example of the smaller, economically distressed communities often overlooked in broader climate adaptation strategies. Salem, with its population of approximately 5,296, majority of whom are Black (59%), and a high poverty rate (39%), exemplifies the compounded challenges faced by similar municipalities. Over the years, Salem has experienced a 42% population decline since 1950, enhancing its vulnerability to economic and environmental stresses, including a 90% flood risk. Additionally, the city is burdened with failing drinking water infrastructure and abundant vacant land, yet it holds potential for waterfront redevelopment. By studying Salem, we aimed to identify common challenges and explore the efficacy of potential solutions that could be applied to similar towns facing high climate risks, thus ensuring a focused and impactful adaptation strategy. Through this study and comparison with similar places, we identified the following core, common challenges.\n\n2.3.1 Low Population\nThe small size of these communities inherently limits their capacity for handling and adapting to change, particularly in the context of climate adaptation. Limited administrative resources, reduced civic engagement, and a scarcity of local expertise all contribute to these challenges. These constraints are often more pronounced in smaller populations, where even basic adaptation measures can be burdensome to implement without adequate human and financial resources.\n\n\n\n\n\n\n\n2.3.2 Low Median Income\nEconomically, these places often grapple with low median incomes and high poverty rates, which exacerbate their vulnerability to climate impacts. Financial constraints limit the ability of these communities to invest in necessary infrastructure improvements or resilience-building projects. This economic strain is not just about limited municipal budgets; it also affects the individual capacity of residents to respond to and recover from climate-related events.\n\n\n\n\n\n\n\n2.3.3 Zero or Negative Population Growth\nMany of these communities have experienced little to no population growth, with some even seeing a decline since the post-industrial era began in the 1960s. This demographic shift results in a scale mismatch, where infrastructure originally built for a larger population must now be maintained by a significantly smaller one. This mismatch strains local budgets, as there are fewer taxpayers to support the cost of maintaining outdated or oversized infrastructure.\n\n\n\n\n\n\n\n2.3.4 High Residential Vacancy Rates\nLinked closely to the problem of population decline is the issue of high residential vacancy rates. As populations shrink, the residential built environment does not contract at the same pace, leading to increased vacancies and the associated economic and social challenges. This scale mismatch can result in the physical deterioration of the urban fabric and further economic decline, creating a negative feedback loop that exacerbates community vulnerability.\n\n\n\n\n\n\n\n2.3.5 Abundant Legacy Industrial Infrastructure\nThese communities often possess substantial legacy industrial infrastructure, which presents both challenges and opportunities. While this infrastructure can sometimes be repurposed to support new industries or community services, it often requires significant investment to update and make it resilient against current and future climate risks. The financial and logistical challenges of retrofitting such infrastructure can be formidable, particularly for communities already struggling economically.\n\n\n\n\n\n\n\n2.3.6 High Flood Risk\nMany of these communities also face high flood risks, which can exacerbate the effects of other vulnerabilities. As noted, sea level rise and other climate-related impacts can mirror the infrastructure and public health challenges already faced by shrinking cities. High flood risk can lead to repeated damages, increasing maintenance costs, and can deter new investment in these areas, further straining local economies.\n\n\n\n\n\n\n\n2.3.7 Legacy Pollution\nLegacy pollution adds another layer of complexity to the challenges faced by these communities. Contaminated sites from previous industrial activities not only pose health risks but also hinder redevelopment efforts, as cleaning up these sites requires substantial financial investment and technical expertise.\n\n\n2.3.8 Social Fragmentation\nSocial fragmentation, characterized by weakened community bonds and decreased social cohesion, further complicates the ability of these areas to collectively respond to environmental and economic challenges. This fragmentation can lead to reduced civic participation and a lack of unified action towards community resilience.\n\n\n2.3.9 Degraded Ecosystems\nThe environmental degradation of ecosystems in these areas, often a result of industrial activity and urban expansion, reduces their natural capacity to handle climate impacts like flooding and erosion. Restoring these ecosystems is crucial for enhancing the overall resilience of these communities.\n\n\n2.3.10 Compounding Risk\nThe vulnerabilities faced by smaller, declining communities are complex and interconnected, exacerbating each other in ways that deepen their challenges. Declining populations often go hand in hand with high socioeconomic difficulties, including increased poverty rates and racial segregation. This demographic shrinkage leads to a scale mismatch, where infrastructure and services originally designed for a larger population must now be supported by significantly fewer residents. Additionally, these communities grapple with legacy infrastructure and an abundance of vacant properties, increasing their exposure to climate risks while simultaneously diminishing their financial capacity to fund necessary services and hazard mitigation. The compounded risks intensify the challenges, leading to cycles of increased vulnerability and disadvantage. Struggling with aging and oversized infrastructure that is also at increased risk from climate impacts, these communities face a daunting task: they must manage not only their current vulnerabilities but also the ongoing cycle of economic and demographic decline that continually erodes their ability to effectively respond to environmental and economic challenges.\n\n\n\n2.4 Quantifying Common Vulnerability\nTools like SoVI and CEJST are valuable insofar as they allow us to quantify the vulnerability of places acros the United States. Yet, as mentioned, they can overlook the nuanced differences between the types of vulnerability that manifest in different places. Here, we propose using clustering to more precisely capture the types of vulnerability in New Jersey. Per Stafford and Abramowitz (2017), “Cluster analysis groups like observations which allows a researcher to easily identify areas that may face similar types of social vulnerability and could potentially share adaptation and mitigation solutions.” Accordingly, we employ cluster analysis as a means of understanding distinct typologies of vulnerability as they exist across a range of geographies in New Jersey, in order to identify similar types of socioeconomic, infrastructural, and climatic vulnerability in order to drive shared adaptation and mitigation solutions.\nAbove, we laid out challenges common to small, legacy cities in New Jersey facing climate risks. As a proof of concept, we’ve built a statistical clustering model that combines data on these factors to produce a list of municipalities across New Jersey that we identify as worthy of further investigation. These constitute small and mid-sized cities with limited financial resources, significant urban issues (e.g., high vacancy), and significant climate vulnerability. This is a proof of concept that can (and eventually should) be updated with more granular data, including on other climate hazards. However, in the short term, it is an effective tool for motivating further research into these places.\nFirst, we identify a list of indicators that capture the trends we outline above. Using correlation analyses and feature engineering, we reduce this to the most parsimonious possible set of variables, which we then feed into our clustering model.\n\n\n\n\n\n\n\n\n\nVariable\nSource\nSpatial Resolution\nTime Period\n\n\n\n\nTotal population\nCensus Bureau\nMunicipality\n2020\n\n\nMedian income\nAmerican Community Survey\nCensus tract\n2020\n\n\nPopulation change\nCensus Bureau\nMunicipality\n1950 - 2020\n\n\nResidential vacancy\nCensus Bureau\nCensus tract\n2020\n\n\nFlood risk\nCEJST\nCensus tract\n2020\n\n\nIndustrial infrastructure\nNational Land Cover Dataset (USGS)\n30 meters\n2021\n\n\n\nTo prepare for clustering, we select and transform variables as appropriate. We have no multicolinearity in our dataset and normalize variable distributions as needed. We then apply principal component analysis (PCA) to retain only the necessary components for clustering, while reducing redundancy. We select 3 clusters based on a combination of elbow plot and silhouette scores, seeking to achieve the fewest number of meaningful, interpretable clusters. Finally, we run 100 iterations of k-means clustering using the diceR package in order to ensure consistent outputs and reproducibility. Code is available on GitHub for further details."
  },
  {
    "objectID": "index.html#feature-selection-and-engineering",
    "href": "index.html#feature-selection-and-engineering",
    "title": "MACH Superstudio Clustering",
    "section": "3 Feature Selection and Engineering",
    "text": "3 Feature Selection and Engineering\n\n3.1 Variable Selection\n\n3.1.1 Total Population\n\n\n\n\n\n\n\n3.1.2 Income\n\n\n3.1.3 Population Change\n\n\n\n\n\n\n\n3.1.4 Industrial Development\n\n\n\n\n\n\n\n3.1.5 Residential Vacancy\n\n\n3.1.6 Flood Risk\n\n\n\n\n\n\n\n\n3.2 Exploratory Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Selection and Engineering"
  },
  {
    "objectID": "index.html#clustering",
    "href": "index.html#clustering",
    "title": "MACH Superstudio Clustering",
    "section": "3 Clustering",
    "text": "3 Clustering\nTo prepare for clustering, we select and transform variables as appropriate. We have no multicolinearity in our dataset and normalize variable distributions as needed. We then apply principal component analysis (PCA) to retain only the necessary components for clustering, while reducing redundancy. We select 3 clusters based on a combination of elbow plot and silhouette scores, seeking to achieve the fewest number of meaningful, interpretable clusters. Finally, we run 100 iterations of k-means clustering using the diceR package in order to ensure consistent outputs and reproducibility. Code is available on GitHub for further details."
  },
  {
    "objectID": "index.html#results",
    "href": "index.html#results",
    "title": "MACH Superstudio Clustering",
    "section": "3 Results",
    "text": "3 Results\nOur clustering model produces three clusters:\n\nCluster 1 comprises roughly 160 municipalities representing only about 75,000 people. Its municipalities have by far the smallest populations on average. They experience fairly high median incomes, small but positive population growth, and low industrial development. They only stand out in terms of flood risk, for which they have the highest scores. These places are vulnerable to climate risks, and may lack adaptive capacity due to their small size, but generally have significant financial resources to address these challenges.\nCluster 2 represents just under 300 municipalities in New Jersey, including nearly 6,000,000 residents. It has high incomes, low flood risk, the highest levels of population growth, low levels of industrial development, and medium to large populations. Places in this cluster generally are not considered vulnerable for our purposes.\nCluster 3 accounts for the remaining 100 or so municipalities and slightly more than 2,500,000 residents. It has by far the highest poverty rates, little or even negative population change, the highest levels of industrial development, and generally small populations on average. It also has significant flood risk, with an average risk of nearly 60%. Places in Cluster 2 sit at the intersection of high risks: both socioeconomic and climatic factors compound to make these places exceptionally vulnerable due to their limited financial resources, low adaptive capacity, and high climate vulnerability. These are the places that this analysis has sought to identify."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "MACH Superstudio Clustering",
    "section": "4 Discussion",
    "text": "4 Discussion\nIn our analysis, we have developed a tool that allows us to refine our focus to a list of fewer than 50 municipalities in New Jersey, identifying them as small, legacy cities at high risk of climate change impacts. This prioritization is crucial as these cities not only require funding but also substantial support in building adaptive capacity. Our approach emphasizes the need for comprehensive support strategies, suggesting that attention must be devoted not just to financial assistance but also to enhancing local capacities. This could involve the provision of specialized training, augmentation of local resources, and exploration of innovative governance structures that can empower these communities to effectively manage and implement climate adaptation strategies.\nTo refine our list and ensure we target municipalities with both significant need and some foundational capacity to utilize aid effectively, we employed specific criteria. We excluded places with a population of 500 or fewer on the grounds that their extremely limited administrative and financial resources render them nearly incapable of undertaking substantive climate adaptation measures independently. Furthermore, to focus on areas with critical needs, we also filtered out municipalities where the flood risk is below the average observed in the cluster, concentrating our efforts on those with a flood risk of approximately 55% or greater, and with populations ranging from 500 to 100,000. This methodology helps in pinpointing places that are not only in urgent need but also possess enough of an infrastructural baseline to implement and benefit from targeted interventions. Our final list represents a strategic starting point for deeper investigation and intervention, marking a significant step forward in aligning climate adaptation resources with municipalities where the intersection of need and existing capacity can be optimally leveraged for impactful outcomes.\n\n4.1 Final Suggested Sites\n\n\n\n\n\n\n\n\n\n\n\n\n\nrank\nname\ntot_pop_2020\nmed_inc\nflood_risk\npct_res_vac\nhigh_dens_indust\npct_pop_change\n\n\n\n\n1\nWildwood\n5,157\n27,428\n0.99\n67.40\n0.55\n-5.81\n\n\n2\nBurlington\n9,743\n35,306\n0.98\n10.14\n0.10\n-19.15\n\n\n3\nKeansburg\n9,755\n29,826\n0.98\n18.81\n0.01\n75.48\n\n\n4\nAtlantic City\n38,497\n20,018\n0.97\n23.66\n0.15\n-37.56\n\n\n5\nVentnor City\n9,210\n30,368\n0.97\n40.94\n0.18\n12.90\n\n\n6\nDowne\n1,399\n22,670\n0.97\n43.45\n0.00\n-21.67\n\n\n7\nCape May\n2,768\n31,538\n0.96\n66.17\n0.09\n-23.26\n\n\n8\nEgg Harbor City\n4,396\n22,436\n0.90\n12.46\n0.01\n14.54\n\n\n9\nCarneys Point\n8,637\n25,213\n0.90\n9.53\n0.03\n28.58\n\n\n10\nSalem\n5,296\n17,016\n0.90\n26.34\n0.07\n-41.48\n\n\n11\nEast Newark\n2,594\n23,684\n0.87\n5.94\n0.72\n19.37\n\n\n12\nMaurice River\n6,218\n12,482\n0.86\n21.09\n0.00\n119.41\n\n\n13\nCommercial\n4,669\n24,862\n0.84\n14.96\n0.00\n44.19\n\n\n14\nPenns Grove\n4,837\n21,287\n0.83\n15.59\n0.08\n-27.47\n\n\n15\nWoodlynne\n2,902\n25,938\n0.82\n11.34\n0.08\n4.54\n\n\n16\nRiverside\n8,003\n34,216\n0.81\n10.29\n0.09\n11.17\n\n\n17\nPennsville\n12,684\n32,663\n0.81\n12.68\n0.04\n71.96\n\n\n18\nBeverly\n2,499\n32,785\n0.78\n22.60\n0.03\n-18.97\n\n\n19\nWestville\n4,264\n30,845\n0.78\n9.07\n0.07\n-9.87\n\n\n20\nDunellen\n7,637\n33,830\n0.77\n9.27\n0.08\n21.40\n\n\n21\nKearny\n41,999\n34,908\n0.76\n4.92\n0.31\n5.12\n\n\n22\nElmwood Park\n21,422\n33,887\n0.74\n4.74\n0.19\n39.23\n\n\n23\nPleasantville\n20,629\n21,917\n0.71\n12.45\n0.08\n72.80\n\n\n24\nMannington\n1,475\n30,309\n0.70\n14.65\n0.00\n-12.51\n\n\n25\nAbsecon\n9,137\n30,218\n0.69\n12.22\n0.02\n287.98\n\n\n26\nFairview\n15,025\n31,231\n0.69\n3.45\n0.50\n73.48\n\n\n27\nNewton\n8,374\n33,404\n0.67\n12.32\n0.07\n44.85\n\n\n28\nFairfield\n5,546\n24,167\n0.66\n13.87\n0.00\n190.98\n\n\n29\nDover\n18,460\n28,702\n0.66\n5.28\n0.12\n65.20\n\n\n30\nLinden\n43,738\n34,726\n0.66\n6.31\n0.39\n42.73\n\n\n31\nMount Holly\n9,981\n34,967\n0.65\n10.28\n0.07\n21.63\n\n\n32\nCamden\n71,791\n16,986\n0.65\n13.10\n0.28\n-42.36\n\n\n33\nNational Park\n3,026\n31,520\n0.64\n6.99\n0.02\n25.09\n\n\n34\nLong Branch\n31,667\n29,915\n0.64\n18.02\n0.12\n37.15\n\n\n35\nPhillipsburg\n15,249\n28,963\n0.64\n11.23\n0.12\n-19.40\n\n\n36\nPaulsboro\n6,196\n32,743\n0.63\n16.56\n0.15\n-20.99\n\n\n37\nHackettstown\n10,248\n30,625\n0.62\n3.56\n0.06\n163.17\n\n\n38\nHillside\n22,456\n36,527\n0.61\n5.39\n0.24\n6.90\n\n\n39\nHaledon\n9,052\n35,500\n0.60\n2.45\n0.15\n45.91\n\n\n40\nTrenton\n90,871\n22,597\n0.58\n17.19\n0.30\n-29.01\n\n\n41\nManville\n10,953\n34,205\n0.58\n6.92\n0.12\n27.40\n\n\n42\nMillville\n27,491\n31,122\n0.57\n9.13\n0.03\n71.38\n\n\n43\nBelleville\n38,222\n37,824\n0.57\n7.70\n0.21\n19.37\n\n\n44\nPlainfield\n54,586\n27,532\n0.57\n7.25\n0.07\n28.84\n\n\n45\nGloucester City\n11,484\n28,488\n0.56\n6.73\n0.22\n44.42\n\n\n46\nGarfield\n32,655\n32,633\n0.55\n5.73\n0.35\n18.53\n\n\n47\nElmer\n1,347\n39,694\n0.55\n7.11\n0.05\n-7.74\n\n\n48\nSussex\n2,024\n26,957\n0.55\n16.51\n0.06\n31.34"
  },
  {
    "objectID": "index.html#recommendations",
    "href": "index.html#recommendations",
    "title": "MACH Superstudio Clustering",
    "section": "5 Recommendations",
    "text": "5 Recommendations\nOne flaw in using vulnerability indices to direct funding is that it presumes vulnerability can be effectively addressed by simply adjusting funding levels. This approach overlooks the complex nature of vulnerability, which manifests differently across various contexts, making a one-size-fits-all funding strategy inadequate. Emphasizing the notion that vulnerability manifests in diverse ways is crucial. For instance, while larger urban areas might face significant impacts, they often have more robust infrastructures and administrative capacities to utilize larger funding streams effectively. In contrast, smaller, more isolated communities may not benefit from increased funding alone without tailored approaches that consider their specific challenges and capacities.\nThe smaller, climate-vulnerable places that we highlight here deserve adaptation funding not because they are more vulnerable according to conventional indices, but because their vulnerabilities are distinct. These communities face a unique set of adaptation challenges that do not present themselves in the same manner as in larger urban areas. For example, cities like Trenton and Newark may lack substantial contiguous vacant land that can be converted into nature-based solutions to mitigate climate hazards—a strategy that smaller places like Salem City could implement. Therefore, smaller cities in New Jersey should not be viewed merely as liabilities—too small to justify funding, too vulnerable for sustainable habitation—but rather as potential hubs for innovative climate adaptation practices. This shift in perspective underscores the need for policies and solutions that are specifically designed to leverage the unique opportunities and address the particular challenges faced by these smaller communities.\nAbove, we have advanced an argument for funding coastal climate adaptation in New Jersey’s smaller towns. We’ve identified common traits shared between these places and, based off of these traits, proposed a framework to identify them using a data-driven approach. Furthermore, we have explored a range of potential interventions and directions of inquiry to develop techniques and questions for tackling the unique challenges and opportunities for climate adaptation in these places. Based on the considerations laid out above—as well as the questions that have arisen—we outline a set of next steps to guide future thinking about how to promote effective climate adaptation in these places.\n\n5.1 Integrate with Existing Analyses\nVarious initiatives across New Jersey, such as the New Jersey Department of Environmental Protection, the New Jersey Regional Greenhouse Gas Initiative, and the New Jersey Restoration Tool Organization Suite, are actively engaged in climate adaptation and mitigation efforts. To amplify the effectiveness of these efforts, future research should aim to integrate with and build upon these existing projects. This approach would foster collaboration, reduce redundancy, and maximize the overall impact of climate adaptation strategies. By breaking down silos and encouraging partnerships, researchers and practitioners can leverage collective resources and knowledge, facilitating more comprehensive and robust solutions tailored to the unique environmental challenges facing New Jersey.\n\n\n5.2 Fill Data Gaps\nThis analysis underscores the importance of discerning nuanced differences within broader trends, yet it serves primarily as a proof of concept. The data utilized, while informative, lack the granularity needed for more targeted interventions. To enhance the effectiveness of this research, several steps are recommended for future studies:\n\nValidate Findings: Engage with communities identified as vulnerable through a variety of qualitative methods such as web searches, interviews, and power mapping. The objective here is to corroborate and refine the quantitative data, adding layers of nuance that will inform more actionable solutions.\nIdentify More Granular Data: Pursue finer-scale data collection, such as parcel-level land ownership and high-resolution landcover, which can pinpoint specific areas for targeted climate adaptation efforts.\nUse Data to Drive Action: Data must be leveraged to persuade relevant stakeholders—including those in both the public and private sectors—to allocate climate adaptation financing to smaller, underserved communities in New Jersey. It is crucial to consider how to construct a narrative that not only motivates stakeholders but also effectively uses the assembled data to support this narrative, ensuring it resonates with the intended audience.\n\nBy focusing on these areas, the research can move beyond its initial stages to become a tool to drive significant climate adaptation initiatives tailored to the unique needs of New Jersey’s smaller communities.\n\n\n5.3 Identify Common Challenges\nQuantitative and qualitative research play a crucial role in unearthing trends that are common among smaller, legacy cities in New Jersey, particularly those vulnerable to climate hazards. By systematically gathering and analyzing both numerical data and narrative accounts, researchers can form a comprehensive understanding of the unique challenges these cities face. This detailed insight is essential for developing targeted strategies that address the specific needs of these communities. Recognizing the particular vulnerabilities and capacities of these areas allows for the crafting of more effective and sustainable climate adaptation solutions, tailored to the distinct environmental and socio-economic contexts of this particular type of place. Such research not only illuminates the problems but also paves the way for informed decision-making and policy development, ensuring that interventions are both impactful and appropriate for the communities they serve.\n\n\n5.4 Construct Shared Solutions\nIdentifying the common challenges faced by smaller, legacy cities in New Jersey should lead directly to the creation of shared solutions that address these unique obstacles. The specific issues identified necessitate innovative policy and design approaches, such as establishing collaborative regional governance systems to more effectively advocate for and manage adaptation funding, or employing nature-based solutions to enhance the resilience of aging infrastructure. Emphasis should be placed on developing scalable solutions that are not only suitable for modular implementation but also conducive to partnerships and coordination among similar municipalities. Such strategies can leverage shared strengths and resources, enabling a collective response that is both efficient and impactful. Further research into these areas is essential, as it can refine and expand upon the solutions to ensure they effectively meet the distinct needs of these communities. This approach not only addresses the immediate vulnerabilities but also fosters a sustainable model for future adaptation efforts across the state."
  },
  {
    "objectID": "notebooks/retreat_index.html",
    "href": "notebooks/retreat_index.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport colorcet as cc\nfrom matplotlib.colors import ListedColormap\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nimport pyarrow\n\n\nbase_path = '../data/'\n\n\ncluster_dat = gpd.read_file(base_path + 'clustering_data.geojson')\n\n\ncluster_dat.head()\n\n\n\n\n\n\n\n\ngeoid\npov_rt\nflood_risk\nnamelsad\nNAME\ntot_pop_1940\ntot_pop_1950\ntot_pop_1960\ntot_pop_1970\ntot_pop_1980\n...\ndeciduous_forest\nevergreen_forest\nmixed_forest\nshrub_scrub\ngrassland_herbaceous\npasture_hay\ncultivated_crops\nwoody_wetlands\nemergent_herbaceous_wetlands\ngeometry\n\n\n\n\n0\n3400100100\n0.406424\n0.693030\nAbsecon city\nAbsecon city, Atlantic County, New Jersey\n2084.0\n2355.0\n4320.0\n6094.0\n6859.0\n...\n0.015168\n0.001250\n0.028210\n0.000915\n0.001041\n0.002462\n0.003178\n0.080904\n0.251300\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n\n\n1\n3400102080\n0.775740\n0.971788\nAtlantic City city\nAtlantic City city, Atlantic County, New Jersey\n64094.0\n61657.0\n59544.0\n47859.0\n40199.0\n...\n0.000101\n0.000101\n0.000020\n0.000525\n0.000942\n0.000000\n0.000000\n0.014594\n0.311823\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n\n\n2\n3400107810\n0.302975\n0.966959\nBrigantine city\nBrigantine city, Atlantic County, New Jersey\n403.0\n1267.0\n4201.0\n6741.0\n8318.0\n...\n0.000928\n0.000000\n0.000192\n0.001503\n0.005833\n0.000000\n0.000832\n0.015162\n0.287935\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n\n\n3\n3400108680\n0.569470\n0.181154\nBuena borough\nBuena borough, Atlantic County, New Jersey\n3111.0\n2640.0\n3243.0\n3283.0\n3642.0\n...\n0.105284\n0.003854\n0.022989\n0.004221\n0.004542\n0.003341\n0.484193\n0.061991\n0.000315\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n\n\n4\n3400108710\n0.449822\n0.579928\nBuena Vista township\nBuena Vista township, Atlantic County, New Jersey\n4067.0\n2106.0\n3915.0\n4239.0\n6959.0\n...\n0.273240\n0.023212\n0.157290\n0.009062\n0.008720\n0.005383\n0.146850\n0.223212\n0.002444\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n\n\n\n\n5 rows × 32 columns\n\n\n\n\ncluster_dat.columns\n\nIndex(['geoid', 'pov_rt', 'flood_risk', 'namelsad', 'NAME', 'tot_pop_1940',\n       'tot_pop_1950', 'tot_pop_1960', 'tot_pop_1970', 'tot_pop_1980',\n       'tot_pop_1990', 'tot_pop_2000', 'tot_pop_2010', 'tot_pop_2020',\n       'size_class', 'pct_res_vac', 'open_water', 'developed_open_space',\n       'developed_low_intensity', 'developed_medium_intensity',\n       'developed_high_intensity', 'barren_land_rock_sand_clay',\n       'deciduous_forest', 'evergreen_forest', 'mixed_forest', 'shrub_scrub',\n       'grassland_herbaceous', 'pasture_hay', 'cultivated_crops',\n       'woody_wetlands', 'emergent_herbaceous_wetlands', 'geometry'],\n      dtype='object')\n\n\n\ncluster_dat.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n# calculate the pct 70 year pop change from tot_pop_1950 and tot_pop_2020\ncluster_dat['pct_70_year_pop_change'] = ((cluster_dat['tot_pop_2020'] - cluster_dat['tot_pop_1950']) / cluster_dat['tot_pop_1950']) * 100\n\n\n# select the following columns: P200_I_PFS, FLD_PFS, pct_thirty_yr_pop_change, geometry\nretreat_index_gdf = cluster_dat[['pov_rt', 'flood_risk', 'pct_70_year_pop_change', 'developed_high_intensity', 'tot_pop_2020', 'geometry']]\n\n\nretreat_index_gdf.head()\n\n\n\n\n\n\n\n\npov_rt\nflood_risk\npct_70_year_pop_change\ndeveloped_high_intensity\ntot_pop_2020\ngeometry\n\n\n\n\n0\n0.406424\n0.693030\n287.983015\n0.024833\n9137.0\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n\n\n1\n0.775740\n0.971788\n-37.562645\n0.154158\n38497.0\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n\n\n2\n0.302975\n0.966959\n508.997632\n0.058109\n7716.0\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n\n\n3\n0.569470\n0.181154\n70.492424\n0.015367\n4501.0\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n\n\n4\n0.449822\n0.579928\n233.950617\n0.003296\n7033.0\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n\n\n\n\n\n\n\n\n# plot maps of each of the numeric cols in the retreat_index_gdf\nfig, ax = plt.subplots(3, 2, figsize=(14, 20))\nretreat_index_gdf.plot(column='pov_rt', cmap='viridis', ax=ax[0][0])\nax[0][0].set_title('Poverty')\nax[0][0].axis('off')\n\nretreat_index_gdf.plot(column='flood_risk', cmap='viridis', ax=ax[0][1])\nax[0][1].set_title('Flood Risk')\nax[0][1].axis('off')\n\nretreat_index_gdf.plot(column='pct_70_year_pop_change', cmap='viridis', ax=ax[1][0])\nax[1][0].set_title('Pop Change')\nax[1][0].axis('off')\n\nretreat_index_gdf.plot(column='developed_high_intensity', cmap='viridis', ax=ax[1][1])\nax[1][1].set_title('High Density (Industrial)')\nax[1][1].axis('off')\n\nretreat_index_gdf.plot(column='tot_pop_2020', cmap='viridis', ax=ax[2][0])\nax[2][0].set_title('Total Population 2020')\nax[2][0].axis('off')\n\nplt.show()\n\n\n\n\n\n# Exclude non-numeric columns\nnumeric_cols = retreat_index_gdf.select_dtypes(include=[np.number]).columns\n\n# Calculate correlation matrix\ncorr = retreat_index_gdf[numeric_cols].corr()\n\n# Plot correlation matrix\nplt.matshow(corr)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\nplt.yticks(range(len(corr.columns)), corr.columns)\nplt.colorbar()\n\n# Add correlation values\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center', color='w')\n\nplt.show()\n\n\n\n\n\n# Histograms for the four variables\nplt.figure(figsize=(20, 10))\n\n# Function to apply log transformation\ndef log_transform(column):\n    if (column &lt;= 0).any():\n        min_value = column.min()\n        shift_constant = np.abs(min_value) + 1\n        return np.log(column + shift_constant)\n    else:\n        return np.log(column)\n\n# Histogram for Poverty Index\nplt.subplot(2, 3, 1)\ntransformed_pov_rt = log_transform(retreat_index_gdf['pov_rt'])\nplt.hist(transformed_pov_rt, bins=20, color='skyblue', edgecolor='black')\nplt.xlabel('Transformed Poverty Index')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Poverty Index')\n\n# Histogram for Flood Risk\nplt.subplot(2, 3, 2)\nplt.hist(retreat_index_gdf['flood_risk'], bins=20, color='lightgreen', edgecolor='black')\nplt.xlabel('Flood Risk')\nplt.ylabel('Frequency')\nplt.title('Distribution of Flood Risk')\n\n# Histogram for Population Change\nplt.subplot(2, 3, 3)\ntransformed_pop_change = log_transform(retreat_index_gdf['pct_70_year_pop_change'])\nplt.hist(transformed_pop_change, bins=20, color='salmon', edgecolor='black')\nplt.xlabel('Transformed Population Change')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Population Change')\n\n# Histogram for Developed High Intensity\nplt.subplot(2, 3, 4)\ntransformed_developed_high_intensity = np.sqrt(retreat_index_gdf['developed_high_intensity'])\nplt.hist(transformed_developed_high_intensity, bins=20, color='purple', edgecolor='black')\nplt.xlabel('Square Root Transformed Developed High Intensity')\nplt.ylabel('Frequency')\nplt.title('Distribution of Square Root Transformed Developed High Intensity')\n\n\n# Histogram for Total Population\nplt.subplot(2, 3, 5)\ntransformed_tot_pop_2020 = log_transform(retreat_index_gdf['tot_pop_2020'])\nplt.hist(transformed_tot_pop_2020, bins=20, color='orange', edgecolor='black')\nplt.xlabel('Transformed Total Population 2020')\nplt.ylabel('Frequency')\nplt.title('Distribution of Log Transformed Total Population 2020')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Step 1: Apply transformations\nretreat_index_gdf['log_pov_rt'] = np.log(retreat_index_gdf['pov_rt'])\nretreat_index_gdf['log_tot_pop_2020'] = np.log(retreat_index_gdf['tot_pop_2020'])\nretreat_index_gdf['sqrt_flood_risk'] = np.sqrt(retreat_index_gdf['flood_risk'])\nretreat_index_gdf['squared_developed_high_intensity'] = retreat_index_gdf['developed_high_intensity'] ** 2\n\n# Step 2: Z-score normalize the variables\nscaler = StandardScaler()\nvariables_to_normalize = ['log_pov_rt', 'sqrt_flood_risk', 'pct_70_year_pop_change', 'squared_developed_high_intensity', 'log_tot_pop_2020']\n# Drop NA values from the dataframe to avoid errors in scaling and clustering\ncleaned_gdf = retreat_index_gdf.dropna(subset=variables_to_normalize)\nnormalized_data = scaler.fit_transform(cleaned_gdf[variables_to_normalize])\nnormalized_df = pd.DataFrame(normalized_data, columns=variables_to_normalize, index=cleaned_gdf.index)\n\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nc:\\Users\\Nissim\\Documents\\GitHub\\mach-superstudio\\.venv\\lib\\site-packages\\geopandas\\geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n# run PCA on the normalized data to show which variables are most important\nfrom sklearn.decomposition import PCA\n\npca = PCA()\npca.fit(normalized_df)\n\n# Plot the explained variance ratio\nplt.figure(figsize=(10, 6))\n\nplt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o')\nplt.xlabel('Principal Component')\nplt.ylabel('Explained Variance Ratio')\n\nplt.show()\n\n\n\n\n\n# show the eigenvalues of each componnet\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(range(1, len(pca.explained_variance_) + 1), pca.explained_variance_, marker='o')\nplt.xlabel('Principal Component')\nplt.ylabel('Eigenvalue')\n\nplt.show()\n\n\n\n\n\n# show which variables are most important in each component\n# Create a DataFrame with the loadings\n\nloadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i}' for i in range(1, len(pca.components_) + 1)], index=variables_to_normalize)\n\n# Plot the loadings\nplt.figure(figsize=(10, 6))\n\nplt.barh(loadings.index, loadings['PC1'])\nplt.xlabel('Loading Value')\nplt.ylabel('Variable')\n\nplt.show()\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Step 1: Compute WCSS for different numbers of clusters\nwcss = []  # List to store WCSS values\ncluster_range = range(1, 11)  # Adjust the range as needed\n\nfor n_clusters in cluster_range:\n    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=42)\n    kmeans.fit(normalized_df)  # Assuming 'normalized_df' is your pre-processed data\n    wcss.append(kmeans.inertia_)  # inertia_ is the WCSS\n\n# Step 2: Plot the elbow plot\nplt.figure(figsize=(10, 6))\nplt.plot(cluster_range, wcss, marker='o', linestyle='-', color='blue')\nplt.title('Elbow Method For Optimal Number of Clusters')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.xticks(cluster_range)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n# Step 3: Cluster the normalized and cleaned data\nkmeans = KMeans(n_clusters=7, random_state=42)  # Adjust the number of clusters as needed\nclusters = kmeans.fit_predict(normalized_df)\n\n\ncleaned_gdf['cluster'] = clusters  # Add cluster labels to the cleaned GeoDataFrame\n\n\n# Step 4: Map the clusters\n# Ensure the GeoDataFrame for plotting includes the cluster information\nretreat_index_gdf = retreat_index_gdf.merge(cleaned_gdf[['cluster']], left_index=True, right_index=True, how='left')\n\n\nretreat_index_gdf.head()\n\n\n\n\n\n\n\n\npov_rt\nflood_risk\npct_70_year_pop_change\ndeveloped_high_intensity\ntot_pop_2020\ngeometry\nlog_pov_rt\nlog_tot_pop_2020\nsqrt_flood_risk\nsquared_developed_high_intensity\ncluster\n\n\n\n\n0\n0.406424\n0.693030\n287.983015\n0.024833\n9137.0\nPOLYGON ((-74.53138 39.42627, -74.52991 39.425...\n-0.900360\n9.120087\n0.832484\n0.000617\n2\n\n\n1\n0.775740\n0.971788\n-37.562645\n0.154158\n38497.0\nPOLYGON ((-74.50159 39.35726, -74.50053 39.356...\n-0.253938\n10.558336\n0.985793\n0.023765\n2\n\n\n2\n0.302975\n0.966959\n508.997632\n0.058109\n7716.0\nPOLYGON ((-74.42199 39.38523, -74.41826 39.381...\n-1.194105\n8.951051\n0.983341\n0.003377\n2\n\n\n3\n0.569470\n0.181154\n70.492424\n0.015367\n4501.0\nPOLYGON ((-74.98262 39.51310, -74.97955 39.510...\n-0.563049\n8.412055\n0.425622\n0.000236\n5\n\n\n4\n0.449822\n0.579928\n233.950617\n0.003296\n7033.0\nPOLYGON ((-74.97211 39.50571, -74.97183 39.505...\n-0.798903\n8.858369\n0.761530\n0.000011\n5\n\n\n\n\n\n\n\n\nretreat_index_gdf.columns\n\nIndex(['pov_rt', 'flood_risk', 'pct_70_year_pop_change',\n       'developed_high_intensity', 'tot_pop_2020', 'geometry', 'log_pov_rt',\n       'log_tot_pop_2020', 'sqrt_flood_risk',\n       'squared_developed_high_intensity', 'cluster'],\n      dtype='object')\n\n\n\n# Select a colorcet palette and create a ListedColormap\ncolors = cc.glasbey_hv[:6]  # For 7 clusters\ncmap = ListedColormap(colors)\n\n# Plotting\nfig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size\nretreat_index_gdf.plot(column='cluster', cmap=cmap, legend=True, ax=ax, categorical=True)\n\n# Adjusting the legend to be outside\nlegend = ax.get_legend()\nif legend:\n    legend.set_bbox_to_anchor((1.2, 1))  # Move the legend further right\n    legend.set_title('Cluster')\n    legend.set_frame_on(False)  # Remove the frame of the legend\n\n# Remove the frame, ticks, and labels\nax.set_frame_on(False)\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the layout to leave space for the legend\nplt.show()\n\n\n\n\n\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Step 1: Apply PCA for 3 components\npca = PCA(n_components=3)\npca_data = pca.fit_transform(normalized_df)\n\n# Step 2: Create a DataFrame with the PCA data\npca_df = pd.DataFrame(pca_data, columns=['PC1', 'PC2', 'PC3'], index=cleaned_gdf.index)\n\n# Step 3: Merge the PCA data with the cluster labels\npca_df = pca_df.merge(cleaned_gdf[['cluster']], left_index=True, right_index=True, how='left')\n\n# Step 4: Plot the clusters in 3D, with custom colors\nfig = plt.figure(figsize=(12, 14))\nax = fig.add_subplot(111, projection='3d')\n\n# Define a color list, changing the color for cluster 5\ncolors = ['blue', 'green', 'red', 'magenta', 'purple', 'gold', 'orange', 'lightblue']\n\n# Sort the clusters\nsorted_clusters = sorted(pca_df['cluster'].unique())\n\nfor cluster in sorted_clusters:\n    cluster_data = pca_df[pca_df['cluster'] == cluster]\n    # Use modulo to avoid index errors if there are more clusters than colors\n    color = colors[cluster % len(colors)]\n    ax.scatter(cluster_data['PC1'], cluster_data['PC2'], cluster_data['PC3'], label=f'Cluster {cluster}', color=color, alpha=0.7)\n    \nax.set_xlabel('Principal Component 1')\nax.set_ylabel('Principal Component 2')\nax.set_zlabel('Principal Component 3')\nax.set_title('3D Clusters in PCA Space')\nax.legend()\n\n# Adjust layout to prevent clipping\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n# Variables to plot\nvariables = ['pov_rt', 'flood_risk', 'pct_70_year_pop_change', 'developed_high_intensity', 'log_tot_pop_2020']\ntitles = ['Poverty Index', 'Flood Risk', 'Population Change', 'High Industry', 'Tot Pop 2020']\n\n# Creating box plots\nfig, axes = plt.subplots(3, 2, figsize=(10, 10))\n\n# Flatten the axes array and iterate over it\nfor ax, var, title in zip(axes.flatten(), variables, titles):\n\n    # Prepare data for plotting: extract values for each cluster\n    data_to_plot = [retreat_index_gdf[retreat_index_gdf['cluster'] == cluster][var] for cluster in sorted(retreat_index_gdf['cluster'].unique())]\n    \n    # Create box plot\n    ax.boxplot(data_to_plot)\n    \n    # Setting titles and labels\n    ax.set_title(title)\n    ax.set_xlabel('Cluster')\n    ax.set_ylabel('Value')\n    ax.set_xticklabels(sorted(retreat_index_gdf['cluster'].unique()))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Create a new column 'highlight' that is True for clusters 2 and 3, and False otherwise\nretreat_index_gdf['highlight'] = retreat_index_gdf['cluster'].isin([1, 2])\n\n# Create a color map for the highlight: use bright colors for True (clusters 2 and 3) and a dull color for False\nhighlight_cmap = ListedColormap(['#aaaaaa', '#ff0000', 'orange'])\n\n# Plotting\nfig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size\nretreat_index_gdf.plot(column='highlight', cmap=highlight_cmap, legend=True, ax=ax, categorical=True)\n\n# Adjusting the legend to be outside\nlegend = ax.get_legend()\nif legend:\n    legend.set_bbox_to_anchor((1.2, 1))  # Move the legend further right\n    legend.set_title('Legacy Cities with Climate Impacts')\n    legend.set_frame_on(False)  # Remove the frame of the legend\n\n# Remove the frame, ticks, and labels\nax.set_frame_on(False)\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the layout to leave space for the legend\nplt.show()\n\n\n\n\n\n# read the nj_cest from a geoparquet file\nnj_cejst = gpd.read_parquet(base_path + 'nj_cejst.parquet')\n\n\nnj_cejst.head()\n\n\n\n\n\n\n\n\nGEOID10\nSF\nCF\nDF_PFS\nAF_PFS\nHDF_PFS\nDSF_PFS\nEBF_PFS\nEALR_PFS\nEBLR_PFS\n...\nAGE_10\nAGE_MIDDLE\nAGE_OLD\nTA_COU_116\nTA_COUNT_C\nTA_PERC\nTA_PERC_FE\nUI_EXP\nTHRHLD\ngeometry\n\n\n\n\n40677\n34015501210\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.43\n0.38\n0.30\n0.36\n...\n0.12\n0.73\n0.13\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.08790 39.71565, -75.08840 39.715...\n\n\n40678\n34015501301\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.54\n0.44\n0.20\n0.36\n...\n0.07\n0.76\n0.16\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.11347 39.73927, -75.11351 39.739...\n\n\n40679\n34015501303\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.54\n0.61\n0.34\n0.39\n...\n0.08\n0.66\n0.24\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.13190 39.72464, -75.13088 39.723...\n\n\n40680\n34015501900\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.40\n0.63\n0.67\n0.39\n...\n0.07\n0.76\n0.16\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.19511 39.66308, -75.19538 39.663...\n\n\n40681\n34015500300\nNew Jersey\nGloucester County\nNaN\nNaN\nNaN\n0.80\n0.57\n0.50\n0.74\n...\n0.10\n0.76\n0.13\nNaN\nNone\nNaN\nNaN\nNation\n21\nPOLYGON ((-75.19502 39.87752, -75.19471 39.877...\n\n\n\n\n5 rows × 124 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap\n\n# Assuming retreat_index_gdf and nj_cest are previously defined GeoDataFrames\n\n# Modify the highlight column to differentiate clusters 1 and 2\nretreat_index_gdf['highlight'] = retreat_index_gdf['cluster'].apply(lambda x: 0 if x not in [1, 2] else (1 if x == 1 else 2))\n\n# Generate colors for the highlight - pick from viridis\nviridis = plt.cm.get_cmap('viridis', 3)  # Get 3 distinct colors from viridis\nhighlight_colors = [viridis.colors[0], viridis.colors[1], viridis.colors[2]]  # Pick colors for clusters 1, 2, and others\nhighlight_cmap = ListedColormap(highlight_colors)\n\n# Set up a figure with two columns and 5 rows (since you'll have 9 plots)\nfig, ax = plt.subplots(4, 2, figsize=(14, 35))  # Adjust size as needed\n\n# Flatten the ax for easy indexing\nax = ax.flatten()\n\n# Define a new colormap for your first plot if needed\nviridis_half = plt.cm.viridis(np.linspace(0, 0.5, 256))\nnewcmp = LinearSegmentedColormap.from_list('HalfViridis', viridis_half)\n\n# Plotting with the custom colormap for 'highlight'\nretreat_index_gdf.plot(column='highlight', cmap=highlight_cmap, ax=ax[0], categorical=True)\nax[0].set_title('Legacy Cities x Climate Index')\nax[0].axis('off')\n\n# Add other plots as before, adjusting ax indexing\n# Example for the second plot\nnj_cejst.plot(column='TC', cmap='viridis', ax=ax[1])\nax[1].set_title('New Jersey CEJST')\nax[1].axis('off')\n\n# Plot for 'pov_rt' (3x3 position: 1,3)\nretreat_index_gdf.plot(column='pov_rt', cmap='viridis', ax=ax[2])\nax[2].set_title('Poverty')\nax[2].axis('off')  # Remove axes and ticks\n\n# Plot for 'flood_risk' (3x3 position: 2,1)\nretreat_index_gdf.plot(column='flood_risk', cmap='viridis', ax=ax[3])\nax[3].set_title('Flood Risk')\nax[3].axis('off')  # Remove axes and ticks\n\n# Plot for 'pct_70_year_pop_change' (3x3 position: 2,2)\nretreat_index_gdf.plot(column='pct_70_year_pop_change', cmap='viridis', ax=ax[4])\nax[4].set_title('Pop Change')\nax[4].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'developed_high_intensity' (3x3 position: 2,3)\nretreat_index_gdf.plot(column='developed_high_intensity', cmap='viridis', ax=ax[5])\nax[5].set_title('High Density (Industrial)')\nax[5].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'tot_pop_2020' (3x3 position: 3,1)\nretreat_index_gdf.plot(column='tot_pop_2020', cmap='viridis', ax=ax[6])\nax[6].set_title('Total Population 2020')\nax[6].axis('off')  # Remove axes and ticks\n\n\n# Plot for 'pct_res_vac' (3x3 position: 3,2)\ncluster_dat.plot(column='pct_res_vac', cmap='viridis', ax=ax[7])\nax[7].set_title('Pct. Residential Vacancy')\nax[7].axis('off')  # Remove axes and ticks\n\n# Adjust layout and show figure\nplt.tight_layout()\nplt.show()\n\nC:\\Users\\Nissim\\AppData\\Local\\Temp\\ipykernel_26408\\1970897904.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  viridis = plt.cm.get_cmap('viridis', 3)  # Get 3 distinct colors from viridis\n\n\n\n\n\n\n# add a histogram showing the total population of each municipality in the 'highlight' column\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Filter DataFrame for rows where 'highlight' is True, apply log transformation to 'tot_pop_2020', and plot histogram\nnp.log1p(retreat_index_gdf[retreat_index_gdf['highlight']]['tot_pop_2020']).plot.hist(ax=ax, bins=30, color='orange', edgecolor='black')\nplt.xlabel('Log-transformed Total Population')\nplt.ylabel('Frequency')\nplt.title('Log-transformed Total Population of Legacy Cities with Climate Impacts')\n\nplt.show()\n\n\n\n\n\n# print out a list of the municipalities in the highlight column where the log-transformed total population is within 2 standard deviations of the mean\n# Calculate the mean and standard deviation of the log-transformed total population\nmean_log_pop = np.log1p(retreat_index_gdf['tot_pop_2020']).mean()\nstd_log_pop = np.log1p(retreat_index_gdf['tot_pop_2020']).std()\n\n# Filter the DataFrame for rows where 'highlight' is True and the log-transformed total population is within 2 standard deviations of the mean\nhighlighted_municipalities = retreat_index_gdf[(retreat_index_gdf['highlight']) & (np.log1p(retreat_index_gdf['tot_pop_2020']) &gt;= mean_log_pop - 2 * std_log_pop) & (np.log1p(retreat_index_gdf['tot_pop_2020']) &lt;= mean_log_pop + 2 * std_log_pop)]\n\n\n# plot the highlighted municipalities on a map\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Plot the base map\nnj_cejst.plot(ax=ax, color='lightgrey', edgecolor='black', linewidth=0.1)\n\n# Plot the highlighted municipalities\nhighlighted_municipalities.plot(ax=ax, color='pink', edgecolor='black', linewidth=0.5)\n\n# Add a title\n\nplt.title('Highlighted Municipalities with Total Population within 2 Standard Deviations of the Mean')\n\n# Remove the axis\nax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "scratch/gee_raster_data.html",
    "href": "scratch/gee_raster_data.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "import ee\nimport geemap\nimport geopandas as gpd\nimport pygris\nfrom pygris import states\nimport rasterio\nimport fiona\n\n\n# ee.Authenticate()\nee.Initialize(project='hotspotstoplight')\n\n\n            \n            \n\n\nTo authorize access needed by Earth Engine, open the following\n        URL in a web browser and follow the instructions:\n        https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=23lWhyvJb_0H9ODqEadyJyaJ54aAZOx9-Iww00OuC4k&tc=TrfrhhGv7I4TuFL127PDhXDF5ijTZAceQT24GK7SOb4&cc=-l57KD7iq9DfNgLPG12iy3GAt4uaXWgs4Mn1M-2Fm_w\n        The authorization workflow will generate a code, which you should paste in the box below.\n        \n\n\n\nSuccessfully saved authorization token.\n\n\n\nus = states(cb = True, resolution = \"20m\")\nnj = us[us['NAME'] == 'New Jersey']\nnj_ee = geemap.geopandas_to_ee(nj)\n\n# Create a Map\nMap = geemap.Map()\n\nMap.addLayerControl()\n\n# Filter the NLCD Tree Canopy Cover (TCC) for 2021 and CONUS\ndataset = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/TCC/v2021-4')\ntcc = dataset.filter(ee.Filter.calendarRange(2021, 2021, 'year')) \\\n             .filter(ee.Filter.eq('study_area', 'CONUS')) \\\n             .first() \\\n             .clip(nj_ee)  # Clip to NJ boundaries\n\n# Add TCC layer\nMap.addLayer(tcc.select('NLCD_Percent_Tree_Canopy_Cover'), {'min': 0, 'max': 60, 'palette': tcc_palette}, 'NLCD Percent Tree Canopy Cover')\n\n# World Settlement Footprint (WSF) 2015 clipped to NJ\nwsf_dataset = ee.Image('DLR/WSF/WSF2015/v1').clip(nj_ee)\nMap.addLayer(wsf_dataset, wsf_vis, 'Human settlement areas')\n\n# Population Density clipped to NJ\npopulation_dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Population_Density').first().clip(nj_ee)\nMap.addLayer(population_dataset, population_vis, 'Population Density')\n\n# Global Tidal Wetland Change 2019 clipped to NJ\ntidal_dataset = ee.Image('JCU/Murray/GIC/global_tidal_wetland_change/2019').clip(nj_ee)\nMap.addLayer(tidal_dataset.select('loss'), {'palette': loss_palette, 'min': 1, 'max': 1}, 'Tidal Wetland Loss')\nMap.addLayer(tidal_dataset.select('gain'), {'palette': gain_palette, 'min': 1, 'max': 1}, 'Tidal Wetland Gain')\n\n# Bio-Intactness Dataset clipped to NJ\nbdi_ic = ee.ImageCollection(\"projects/ebx-data/assets/earthblox/IO/BIOINTACT\").mean().clip(nj_ee)\nMap.addLayer(bdi_ic, bdi_vis, \"Bio-Intactness\")\n\n# Biodiversity, Carbon, and Water datasets clipped to NJ\nbiodiv_biome_clipped = biodiv_biome.clip(nj_ee)\nbiodivcarbon_clipped = biodivcarbon.clip(nj_ee)\nbiodivcarbonwater_clipped = biodivcarbonwater.clip(nj_ee)\n\n# Add Biodiversity and Carbon layers\nMap.addLayer(biodivcarbon_clipped, biodiv_carbon_vis, \"Biodiversity and Carbon\")\nMap.addLayer(biodivcarbonwater_clipped, biodiv_carbon_vis, \"Biodiversity, Carbon, and Water\")\n\n# Global Forest Change dataset clipped to NJ\ngfc_dataset = ee.Image('UMD/hansen/global_forest_change_2022_v1_10').clip(nj_ee)\nMap.addLayer(gfc_dataset, treeCoverVisParam, 'Tree Cover')\nMap.addLayer(gfc_dataset, treeLossVisParam, 'Tree Loss Year')\n\n# Set the map center to New Jersey with an appropriate zoom level\nMap.setCenter(-74.4057, 40.0583, 7)  # Longitude, Latitude, Zoom Level\n\n# Show the map\nMap\n\n\n            \n            \n\n\n\ndef export_to_drive(image, description, folder, region, scale=250):\n    task = ee.batch.Export.image.toDrive(\n        image=image,\n        description=description,\n        folder=folder,\n        scale=scale,\n        region=region.geometry().bounds().getInfo()['coordinates'],\n        fileFormat='GeoTIFF'\n    )\n    task.start()\n\n# Assuming 'nj_ee' is your Earth Engine geometry for New Jersey\n# Assuming each dataset is clipped to 'nj_ee' and ready for export\n\n# Dictionary of datasets and their names for export\ndatasets = {\n    'TCC_NJ': tcc.select('NLCD_Percent_Tree_Canopy_Cover'),\n    'WSF2015_NJ': wsf_dataset,\n    'PopulationDensity_NJ': population_dataset,\n    'TidalWetlandChange2019_NJ': tidal_dataset,\n    # Add more datasets here as needed\n}\n\n# Folder name in Google Drive\nfolder_name = \"MACH Studio Data\"\n\n# Iterate over the datasets dictionary and export each\nfor description, image in datasets.items():\n    export_to_drive(image, description, folder_name, nj_ee)\n\nprint(\"Export tasks started. Check the 'Tasks' tab in the Google Earth Engine Code Editor for progress.\")"
  },
  {
    "objectID": "SETUP.html",
    "href": "SETUP.html",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow these steps to set up the project environment:\n\n\nFollow the instructions at https://github.com/pypa/pipx to install pipx.\n\n\n\nFollow the instructions at https://github.com/pyenv/pyenv to install pyenv.\n\n\n\nVisit https://python-poetry.org/docs/ for instructions on installing Poetry.\n\n\n\nClone the git repository to your local machine by running the following command in your command line interface (CLI):\ngit clone git@github.com:nlebovits/mach-superstudio.git\n\n\n\nIn your command line interface (CLI), navigate to /mach-superstudio and then run poetry install.\n\n\n\nExecute the following to create a virtual environment in the project directory:\npoetry config virtualenvs.in-project true\n\n\n\nActivate the virtual environment by running:\npoetry shell\nIf using VS Code, you might need to specify the path to the virtual environment. Run the following command to get the path:\npoetry env info --path\nCopy the output path and paste it into VS Code’s Python interpreter path setting. You should now be ready to run the scripts in VS Code."
  },
  {
    "objectID": "SETUP.html#install-pipx",
    "href": "SETUP.html#install-pipx",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow the instructions at https://github.com/pypa/pipx to install pipx."
  },
  {
    "objectID": "SETUP.html#install-pyenv",
    "href": "SETUP.html#install-pyenv",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Follow the instructions at https://github.com/pyenv/pyenv to install pyenv."
  },
  {
    "objectID": "SETUP.html#install-poetry",
    "href": "SETUP.html#install-poetry",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Visit https://python-poetry.org/docs/ for instructions on installing Poetry."
  },
  {
    "objectID": "SETUP.html#clone-the-github-repository",
    "href": "SETUP.html#clone-the-github-repository",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Clone the git repository to your local machine by running the following command in your command line interface (CLI):\ngit clone git@github.com:nlebovits/mach-superstudio.git"
  },
  {
    "objectID": "SETUP.html#install-dependencies-with-poetry",
    "href": "SETUP.html#install-dependencies-with-poetry",
    "title": "Mach Superstudio",
    "section": "",
    "text": "In your command line interface (CLI), navigate to /mach-superstudio and then run poetry install."
  },
  {
    "objectID": "SETUP.html#configure-poetry-virtual-environment",
    "href": "SETUP.html#configure-poetry-virtual-environment",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Execute the following to create a virtual environment in the project directory:\npoetry config virtualenvs.in-project true"
  },
  {
    "objectID": "SETUP.html#activate-the-virtual-environment",
    "href": "SETUP.html#activate-the-virtual-environment",
    "title": "Mach Superstudio",
    "section": "",
    "text": "Activate the virtual environment by running:\npoetry shell\nIf using VS Code, you might need to specify the path to the virtual environment. Run the following command to get the path:\npoetry env info --path\nCopy the output path and paste it into VS Code’s Python interpreter path setting. You should now be ready to run the scripts in VS Code."
  },
  {
    "objectID": "index.html#clustering-1",
    "href": "index.html#clustering-1",
    "title": "MACH Superstudio Clustering",
    "section": "4 Clustering",
    "text": "4 Clustering\n\n4.1 Cluster Number Selection\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Clustering"
  },
  {
    "objectID": "index.html#conclusions",
    "href": "index.html#conclusions",
    "title": "MACH Superstudio Clustering",
    "section": "6 Conclusions",
    "text": "6 Conclusions\nThe approach we have outlined in this report provides a valuable framework for enhancing climate adaptation efforts in New Jersey’s smaller, often overlooked communities. It complements tools like the Federal government’s Climate and Economic Justice Screening Tool (CEJST), by spotlighting places that, while recognized by CEJST, may still be neglected in terms of funding allocation due to their unique vulnerabilities and capacities. This methodology not only highlights the necessity of tailored adaptation strategies but also underscores the importance of fine-tuning these approaches to better assess and address the specific capacities of these communities.\nTo build upon the initial findings and extend the depth of our analysis, we recommend taking several next steps. These include ground-truthing our data, which involves engaging directly with the communities identified as vulnerable, to ensure the accuracy and relevance of our insights. Further integration with ongoing climate adaptation initiatives across the state will also be crucial, as it allows for a more coordinated and comprehensive approach to addressing the challenges these smaller communities face. Additionally, an expanded data collection effort focusing on funding allocation and more granular local data will fill existing gaps and provide a clearer picture of where resources are most needed.\nBy identifying common challenges and constructing shared solutions, we can develop targeted strategies that not only address the immediate needs but also build long-term resilience. This research thus sets the stage for a more informed and effective allocation of climate adaptation resources, ensuring that all communities, regardless of their size or current capacity, are equipped to face the challenges posed by a changing climate. This approach does not merely adapt to current conditions but anticipates future challenges, fostering a proactive and inclusive model for climate resilience in New Jersey."
  }
]